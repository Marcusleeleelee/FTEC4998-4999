{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marcusleeleelee/FTEC4998-4999/blob/main/FTEC4998_4999.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Irism69Bo6L",
        "outputId": "31dbe037-6bce-4078-c1bd-da3843e5e199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabpfn in /usr/local/lib/python3.10/dist-packages (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (1.3.2)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tabpfn) (2.4.0+cu121)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->tabpfn) (2024.7.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->tabpfn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->tabpfn) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->tabpfn) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->tabpfn) (1.3.0)\n",
            "Requirement already satisfied: torchview in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-learn models and utilities\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Scikit-learn utilities\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# PyTorch for neural network models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Progress bar for loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Plotting accuracy curves and other metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Others\n",
        "import inspect\n",
        "!pip install tabpfn\n",
        "from tabpfn.scripts.decision_boundary import DecisionBoundaryDisplay\n",
        "from tabpfn import TabPFNClassifier\n",
        "from matplotlib.colors import ListedColormap\n",
        "!pip install torchview\n",
        "from torchview import draw_graph\n",
        "import warnings; warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Google Colab specific (if needed)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lmLx5bbgBtcq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, file_path):\n",
        "        self.dataset = pd.read_feather(file_path)\n",
        "        self.original = self.dataset.copy()\n",
        "        self.X_train, self.y_train = None, None\n",
        "        self.X_valid, self.y_valid = None, None\n",
        "        self.X_test, self.y_test = None, None\n",
        "        self.label = 'loan_condition_cat'\n",
        "        self.min_max_columns = ['annual_inc', 'year']\n",
        "        self.means = {}\n",
        "        self.stds = {}\n",
        "        self.mins = {}\n",
        "        self.maxs = {}\n",
        "\n",
        "    def show(self, rows=10):\n",
        "        return self.dataset.head(rows)\n",
        "\n",
        "    def basic_processing(self):\n",
        "        temp_func_2 = lambda x: {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}[str(x)]\n",
        "        columns_to_delete = [\n",
        "            'id', 'issue_d', 'home_ownership_cat', 'income_category', 'income_cat', 'term_cat',\n",
        "            'application_type_cat', 'purpose_cat', 'interest_payment_cat', 'loan_condition'\n",
        "        ]\n",
        "        self.dataset.drop(columns=columns_to_delete, inplace=True)\n",
        "        self.dataset['grade'] = self.dataset['grade'].apply(temp_func_2)\n",
        "        self.dataset['final_d'] = self.dataset['final_d'].apply(lambda x: str(x)[-4:]).apply(int)\n",
        "        self.dataset['year'] = self.dataset['year'].apply(lambda x: str(x)[-4:]).apply(int)\n",
        "        self.dataset = pd.get_dummies(self.dataset, columns=['home_ownership', 'term', 'application_type',\n",
        "                                                             'purpose', 'interest_payments', 'region'], dtype=int)\n",
        "\n",
        "    def train_test_split(self, test_size=0.2, valid_size=0.2, random_state=42):\n",
        "        # Split into train and test first\n",
        "        X = self.dataset.drop(columns=[self.label])\n",
        "        y = self.dataset[self.label]\n",
        "        X_train_full, self.X_test, y_train_full, self.y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "        # Further split training data into training and validation sets\n",
        "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(X_train_full, y_train_full, test_size=valid_size, random_state=random_state)\n",
        "\n",
        "        # Save original columns for reference\n",
        "        self.original_columns = X.columns\n",
        "\n",
        "        # Sort and reset index for consistency\n",
        "        for dataset in [self.X_train, self.X_valid, self.X_test, self.y_train, self.y_valid, self.y_test]:\n",
        "            dataset.sort_index(inplace=True)\n",
        "            dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    def preprocessing_train(self):\n",
        "        # Separate columns for Min-Max and Z-score normalization\n",
        "        columns_to_normalize = self.min_max_columns\n",
        "        columns_to_scale = [col for col in self.X_train.columns if col not in columns_to_normalize]\n",
        "\n",
        "        # Z-score normalization\n",
        "        for col in columns_to_scale:\n",
        "            mean = np.mean(self.X_train[col])\n",
        "            std = np.std(self.X_train[col])\n",
        "            self.means[col] = mean\n",
        "            self.stds[col] = std\n",
        "            self.X_train[col] = (self.X_train[col] - mean) / std\n",
        "\n",
        "        # Min-Max normalization\n",
        "        for col in columns_to_normalize:\n",
        "            min_val = np.min(self.X_train[col])\n",
        "            max_val = np.max(self.X_train[col])\n",
        "            self.mins[col] = min_val\n",
        "            self.maxs[col] = max_val\n",
        "            self.X_train[col] = (self.X_train[col] - min_val) / (max_val - min_val)\n",
        "\n",
        "        # Perform PCA\n",
        "        selected_columns = self.perform_pca(self.X_train, n_components=35)\n",
        "        self.X_train = self.X_train[selected_columns]\n",
        "\n",
        "    def perform_pca(self, data, n_components):\n",
        "        # Center the data\n",
        "        data_mean = np.mean(data, axis=0)\n",
        "        centered_data = data - data_mean\n",
        "\n",
        "        # Compute covariance matrix\n",
        "        cov_matrix = np.cov(centered_data, rowvar=False)\n",
        "\n",
        "        # Eigen decomposition\n",
        "        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
        "\n",
        "        # Sort eigenvectors by eigenvalues in descending order\n",
        "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "        sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
        "\n",
        "        # Select the top n_components\n",
        "        selected_eigenvectors = sorted_eigenvectors[:, :n_components]\n",
        "\n",
        "        # Identify important features\n",
        "        feature_importance = np.abs(selected_eigenvectors).sum(axis=1)\n",
        "        important_indices = np.argsort(feature_importance)[::-1][:n_components]\n",
        "\n",
        "        # Return the original column names of these features\n",
        "        important_features = [self.original_columns[i] for i in important_indices]\n",
        "\n",
        "        return important_features\n",
        "\n",
        "    def preprocessing_test(self):\n",
        "        # Separate columns for Min-Max and Z-score normalization\n",
        "        columns_to_normalize = self.min_max_columns\n",
        "        columns_to_scale = [col for col in self.X_test.columns if col not in columns_to_normalize]\n",
        "\n",
        "        # Apply Z-score normalization using training statistics\n",
        "        for col in columns_to_scale:\n",
        "            self.X_test[col] = (self.X_test[col] - self.means[col]) / self.stds[col]\n",
        "\n",
        "        # Apply Min-Max normalization using training statistics\n",
        "        for col in columns_to_normalize:\n",
        "            self.X_test[col] = (self.X_test[col] - self.mins[col]) / (self.maxs[col] - self.mins[col])\n",
        "\n",
        "        # Apply PCA using training components\n",
        "        self.X_test = self.X_test[[i for i in self.X_train.columns.to_list()]]\n",
        "\n",
        "    def preprocessing_valid(self):\n",
        "        # Separate columns for Min-Max and Z-score normalization\n",
        "        columns_to_normalize = self.min_max_columns\n",
        "        columns_to_scale = [col for col in self.X_valid.columns if col not in columns_to_normalize]\n",
        "\n",
        "        # Apply Z-score normalization using training statistics\n",
        "        for col in columns_to_scale:\n",
        "            self.X_valid[col] = (self.X_valid[col] - self.means[col]) / self.stds[col]\n",
        "\n",
        "        # Apply Min-Max normalization using training statistics\n",
        "        for col in columns_to_normalize:\n",
        "            self.X_valid[col] = (self.X_valid[col] - self.mins[col]) / (self.maxs[col] - self.mins[col])\n",
        "\n",
        "        # Apply PCA using training components\n",
        "        self.X_valid = self.X_valid[[i for i in self.X_train.columns.to_list()]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "13kLSUwPBvO9"
      },
      "outputs": [],
      "source": [
        "# Calculating # ok\n",
        "data = Dataset('/content/drive/My Drive/Colab Notebooks/FTEC4998_9/loan_final313_processed.feather')\n",
        "data.basic_processing()\n",
        "data.train_test_split(test_size=0.15, valid_size=0.15)\n",
        "data.preprocessing_train()\n",
        "data.preprocessing_valid()\n",
        "data.preprocessing_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMPCAhUjB4tJ",
        "outputId": "2d831be0-0160-4719-dd4f-7a04c2243e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.61% of the training set belongs to the positive class.\n",
            "Training set shape: (641131, 35), (641131,)\n",
            "Validation set shape: (113141, 35), (113141,)\n",
            "Test set shape: (133107, 35), (133107,)\n",
            "Training type: <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.series.Series'>\n",
            "Validation type: <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.series.Series'>\n",
            "Test type: <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "# Data conversion\n",
        "train_x, train_y = data.X_train, data.y_train\n",
        "valid_x, valid_y = data.X_valid, data.y_valid\n",
        "test_x, test_y = data.X_test, data.y_test\n",
        "\n",
        "# Print the percentage of positive class in the training set\n",
        "counts = np.mean(train_y == 1) * 100\n",
        "print(f\"{counts:.2f}% of the training set belongs to the positive class.\")\n",
        "\n",
        "# Print the shapes of the datasets\n",
        "print(f\"Training set shape: {train_x.shape}, {train_y.shape}\")\n",
        "print(f\"Validation set shape: {valid_x.shape}, {valid_y.shape}\")\n",
        "print(f\"Test set shape: {test_x.shape}, {test_y.shape}\")\n",
        "\n",
        "# Print the types of the datasets\n",
        "print(f\"Training type: {type(train_x)}, {type(train_y)}\")\n",
        "print(f\"Validation type: {type(valid_x)}, {type(valid_y)}\")\n",
        "print(f\"Test type: {type(test_x)}, {type(test_y)}\")\n",
        "\n",
        "# Ensure y_train, y_valid, and y_test are binary\n",
        "assert set(train_y).issubset({0, 1}), \"Target values for train_y must be 0 or 1 for binary classification.\"\n",
        "assert set(valid_y).issubset({0, 1}), \"Target values for valid_y must be 0 or 1 for binary classification.\"\n",
        "assert set(test_y).issubset({0, 1}), \"Target values for test_y must be 0 or 1 for binary classification.\"\n",
        "\n",
        "# Move to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5UL36a0-Tq97"
      },
      "outputs": [],
      "source": [
        "# Train, predict, and accuracy functions\n",
        "def train_model_pt(model): # ok\n",
        "    acc_list = {}\n",
        "    model.train()\n",
        "    for epoch in range(model.epochs):\n",
        "        model.optimizer.zero_grad()\n",
        "        outputs = model(model.train_x)\n",
        "        loss = model.criterion(outputs, model.train_y)\n",
        "        loss.backward()\n",
        "        model.optimizer.step()\n",
        "        acc_list.update({epoch: calculate_accuracy_pt(model, model.train_x, model.train_y)})\n",
        "        if epoch % 50 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "    return acc_list\n",
        "\n",
        "def predict_model_pt(model, X): # ok\n",
        "    if isinstance(X, pd.DataFrame): X = torch.tensor(X.to_numpy(), dtype=torch.float32)  # Convert DataFrame to tensor\n",
        "    X = X.to(next(model.parameters()).device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X).squeeze()\n",
        "        return (outputs > 0.5).float().cpu().numpy()  # Convert to numpy array for output\n",
        "\n",
        "def calculate_accuracy_pt(model, X, y, pred=None): # 95% ok\n",
        "    # Ensure X and y are on the same device as the model\n",
        "\n",
        "    if str(type(X)) != \"<class 'torch.Tensor'>\": X, y = df_to_tensor(X, y)\n",
        "\n",
        "    # Get predictions\n",
        "    predictions = torch.tensor(predict_model_pt(model, X), dtype=torch.float32).to(device) if pred is None else torch.tensor(pred, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Ensure predictions and labels are the same shape\n",
        "    predictions = predictions.squeeze()\n",
        "    y = y.squeeze()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    correct = (predictions == y).sum().item()\n",
        "    accuracy = correct / len(y)\n",
        "    return accuracy\n",
        "\n",
        "def df_to_tensor(x, y, device=device): # ok\n",
        "    assert isinstance(x, pd.DataFrame) and isinstance(y, pd.Series), str((type(x), type(y)))\n",
        "    return (torch.tensor(x.to_numpy(), dtype=torch.float32).to(device),  torch.tensor(y.values.ravel(), dtype=torch.float32).unsqueeze(1).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP model\n",
        "class MLP(nn.Module): # Not yet finish the plot function\n",
        "    def __init__(self, train_x, train_y, lr=0.001):\n",
        "        super(MLP, self).__init__()\n",
        "        self.train_y = torch.tensor(train_y.values.ravel(), dtype=torch.float32).unsqueeze(1).to(device)\n",
        "        self.train_x = torch.tensor(train_x.to_numpy(), dtype=torch.float32).to(device)\n",
        "        self.input_dim = self.train_x.shape[1]\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self._initialize_weights()\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        self.epochs = 50\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.net:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "mlp = MLP(train_x, train_y)\n",
        "mlp.to(device)\n",
        "# graph = draw_graph(mlp, input_size=(1, train_x.shape[1]), device=device)\n",
        "# graph.visual_graph\n",
        "# graph.visual_graph.render(filename='mlp_architecture', format='png')\n",
        "acc_dict = train_model_pt(mlp)\n",
        "pred_train = predict_model_pt(mlp, train_x)\n",
        "accuracy_train = calculate_accuracy_pt(mlp, train_x, train_y, pred_train)\n",
        "pred_valid = predict_model_pt(mlp, valid_x)\n",
        "accuracy_valid = calculate_accuracy_pt(mlp, valid_x, valid_y, pred_valid)\n",
        "pred_test = predict_model_pt(mlp, test_x)\n",
        "accuracy_test = calculate_accuracy_pt(mlp, test_x, test_y, pred_test)\n",
        "print('Train pred:', pred_train)\n",
        "print('Train acc:', accuracy_train)\n",
        "print('Valid pred:', pred_valid)\n",
        "print('Valid acc:', accuracy_valid)\n",
        "print('Test pred:', pred_test)\n",
        "print('Test acc:', accuracy_test)\n",
        "# Extract epochs and accuracies\n",
        "epochs = list(acc_dict.keys())\n",
        "accuracies = list(acc_dict.values())\n",
        "\n",
        "# Plotting accuracy over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, accuracies, marker='o', linestyle='-')\n",
        "plt.title('Training Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "tBjeVS2cTyWh",
        "outputId": "8a35b2a1-4c10-4db6-feaf-9e26ae80e7f7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7049795389175415\n",
            "Train pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Train acc: 0.923898548034645\n",
            "Valid pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Valid acc: 0.9247222492288384\n",
            "Test pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Test acc: 0.9239634279188923\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression as a neural network\n",
        "class LogisticRegressionModel(nn.Module): # Not yet finish the plot function\n",
        "    def __init__(self, train_x, train_y, lr=0.001):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.train_y = torch.tensor(train_y.values.ravel(), dtype=torch.float32).unsqueeze(1).to(device)\n",
        "        self.train_x = torch.tensor(train_x.to_numpy(), dtype=torch.float32).to(device)\n",
        "        self.input_dim = self.train_x.shape[1]\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self._initialize_weights()\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        self.epochs = 600\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.net:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "lrg = LogisticRegressionModel(train_x, train_y)\n",
        "lrg.to(device)\n",
        "ABC = train_model_pt(lrg)\n",
        "pred_train = predict_model_pt(lrg, train_x)\n",
        "accuracy_train = calculate_accuracy_pt(lrg, train_x, train_y, pred_train)\n",
        "pred_valid = predict_model_pt(lrg, valid_x)\n",
        "accuracy_valid = calculate_accuracy_pt(lrg, valid_x, valid_y, pred_valid)\n",
        "pred_test = predict_model_pt(lrg, test_x)\n",
        "accuracy_test = calculate_accuracy_pt(lrg, test_x, test_y, pred_test)\n",
        "print('Train pred:', pred_train)\n",
        "print('Train acc:', accuracy_train)\n",
        "print('Valid pred:', pred_valid)\n",
        "print('Valid acc:', accuracy_valid)\n",
        "print('Test pred:', pred_test)\n",
        "print('Test acc:', accuracy_test)\n",
        "# Extract epochs and accuracies\n",
        "epochs = list(ABC.keys())\n",
        "accuracies = list(ABC.values())\n",
        "\n",
        "# Plotting accuracy over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, accuracies, marker='o', linestyle='-')\n",
        "plt.title('Training Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893
        },
        "id": "_Wxx6iHbm_4u",
        "outputId": "df2d7b91-aa35-4ef0-f4b3-0394e90cb041"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.9161598682403564\n",
            "Epoch 50, Loss: 0.8374332785606384\n",
            "Epoch 100, Loss: 0.772408127784729\n",
            "Epoch 150, Loss: 0.7173776030540466\n",
            "Epoch 200, Loss: 0.6708447933197021\n",
            "Epoch 250, Loss: 0.6318569183349609\n",
            "Epoch 300, Loss: 0.5991731286048889\n",
            "Epoch 350, Loss: 0.5716618895530701\n",
            "Epoch 400, Loss: 0.5482798218727112\n",
            "Epoch 450, Loss: 0.5279086232185364\n",
            "Epoch 500, Loss: 0.5097042322158813\n",
            "Epoch 550, Loss: 0.4931057393550873\n",
            "Train pred: [1. 0. 0. ... 0. 0. 0.]\n",
            "Train acc: 0.9167440039555099\n",
            "Valid pred: [1. 0. 1. ... 0. 0. 0.]\n",
            "Valid acc: 0.9171211143617256\n",
            "Test pred: [0. 0. 1. ... 0. 0. 0.]\n",
            "Test acc: 0.9165483408085224\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABes0lEQVR4nO3deVyU5f7/8fcAwwAq7iyaiVuaC66JpFanXFK0LDO30jylZZoWnUor0+pbVnasY3W0PFmeo6lHLStFizQ1y7RExT3XLAGXTDFUwJn794c/5kigMMMMs72ejwePh3PPfd1zDZejvLmu63ObDMMwBAAAAAC4rCBPdwAAAAAAvB3BCQAAAABKQHACAAAAgBIQnAAAAACgBAQnAAAAACgBwQkAAAAASkBwAgAAAIASEJwAAAAAoAQEJwAAAAAoAcEJAMrJfffdp7i4OKfaTpo0SSaTybUdAnzMoUOHZDKZ9Prrr3u6KwACEMEJQMAzmUyl+lq9erWnu+pxd999t0wmk5566ilPdwVuUBBMLvf1yiuveLqLAOAxJsMwDE93AgA8ac6cOYUe//vf/1Zqaqr+85//FDretWtXRUdHO/06+fn5stlsslgsDre9cOGCLly4oLCwMKdfv6yys7MVHR2tmJgYWa1W/fzzz8yC+ZlDhw6pXr16GjhwoHr27Fnk+datW6tZs2Ye6NlFBf2bMmWK/va3v3msHwACU4inOwAAnnbPPfcUevz9998rNTW1yPE/O3v2rCIiIkr9Omaz2an+SVJISIhCQjz7T/bixYtltVo1a9Ys3XzzzVq7dq1uvPFGj/apOIZh6Pz58woPD/d0V7xSTk6OKlSocMVz2rRpU+LffwAINCzVA4BSuOmmm9S8eXNt2rRJN9xwgyIiIvT0009Lkj799FMlJSWpVq1aslgsatCggV588UVZrdZC1/jzHqdL92u89957atCggSwWi6677jr98MMPhdoWt8fJZDJp9OjRWrJkiZo3by6LxaJmzZppxYoVRfq/evVqtWvXTmFhYWrQoIHeffddh/dNzZ07V127dtVf/vIXXXvttZo7d26x5+3evVt33323atasqfDwcDVu3FjPPPNMoXOOHDmi+++/3/49q1evnkaOHKm8vLzLvl9J+vDDD2UymXTo0CH7sbi4OPXq1UtffPGF2rVrp/DwcL377ruSpA8++EA333yzoqKiZLFY1LRpU02fPr3Yfi9fvlw33nijKlWqpMjISF133XX66KOPJEkTJ06U2WzW8ePHi7QbMWKEqlSpovPnz1/x+7dq1Sp17txZFSpUUJUqVXT77bdr165d9ucXLVokk8mkNWvWFGn77rvvymQyafv27fZju3fv1l133aVq1aopLCxM7dq102effVbs92vNmjV6+OGHFRUVpauuuuqK/Sytgu/7l19+qVatWiksLExNmzbVxx9/XOTcAwcOqF+/fqpWrZoiIiLUoUMHLVu2rMh558+f16RJk3TNNdcoLCxMsbGxuvPOO7V///4i55b0mcnKytKwYcN01VVXyWKxKDY2VrfffnuhvzsA4AhmnACglH777Tf16NFDAwYM0D333GNftvfhhx+qYsWKSk5OVsWKFbVq1So999xzys7O1pQpU0q87kcffaQzZ87owQcflMlk0muvvaY777xTBw4cKHGWat26dfr444/18MMPq1KlSpo2bZr69u2rw4cPq3r16pKkzZs369Zbb1VsbKyef/55Wa1WvfDCC6pZs2ap33tGRoa+/vprzZ49W5I0cOBAvfHGG3r77bcVGhpqPy89PV2dO3eW2WzWiBEjFBcXp/379+vzzz/XSy+9ZL9W+/btderUKY0YMUJNmjTRkSNHtGjRIp09e7bQ9Uprz549GjhwoB588EENHz5cjRs3liRNnz5dzZo102233aaQkBB9/vnnevjhh2Wz2TRq1Ch7+w8//FB//etf1axZM40fP15VqlTR5s2btWLFCg0aNEj33nuvXnjhBS1YsECjR4+2t8vLy9OiRYvUt2/fKy6j/Oqrr9SjRw/Vr19fkyZN0rlz5/TWW2+pY8eOSktLU1xcnJKSklSxYkX997//LTKTt2DBAjVr1kzNmzeXJO3YsUMdO3ZU7dq1NW7cOFWoUEH//e9/1adPHy1evFh33HFHofYPP/ywatasqeeee045OTklfj/Pnj2rEydOFDlepUqVQjOfe/fuVf/+/fXQQw9p6NCh+uCDD9SvXz+tWLFCXbt2lSQdPXpU119/vc6ePasxY8aoevXqmj17tm677TYtWrTI3ler1apevXpp5cqVGjBggMaOHaszZ84oNTVV27dvV4MGDeyvW5rPTN++fbVjxw498sgjiouL07Fjx5SamqrDhw87XaQFQIAzAACFjBo1yvjzP4833nijIcmYMWNGkfPPnj1b5NiDDz5oREREGOfPn7cfGzp0qFG3bl3744MHDxqSjOrVqxsnT560H//0008NScbnn39uPzZx4sQifZJkhIaGGvv27bMf27p1qyHJeOutt+zHevfubURERBhHjhyxH9u7d68REhJS5JqX8/rrrxvh4eFGdna2YRiG8dNPPxmSjE8++aTQeTfccINRqVIl4+effy503Gaz2f88ZMgQIygoyPjhhx+KvE7BecW9X8MwjA8++MCQZBw8eNB+rG7duoYkY8WKFUXOL25sunfvbtSvX9/++NSpU0alSpWMhIQE49y5c5ftd2JiopGQkFDo+Y8//tiQZHz99ddFXudSrVq1MqKioozffvvNfmzr1q1GUFCQMWTIEPuxgQMHGlFRUcaFCxfsxzIzM42goCDjhRdesB+75ZZbjBYtWhT6+2Wz2Yzrr7/eaNSokf1YwferU6dOha55OQV/Jy/3tX79evu5Bd/3xYsX24+dPn3aiI2NNVq3bm0/9uijjxqSjG+++cZ+7MyZM0a9evWMuLg4w2q1GoZhGLNmzTIkGVOnTi3Sr4JxKO1n5vfffzckGVOmTCnxPQNAabFUDwBKyWKxaNiwYUWOX7qX5syZMzpx4oQ6d+6ss2fPavfu3SVet3///qpatar9cefOnSVdXN5Uki5duhT6TXx8fLwiIyPtba1Wq7766iv16dNHtWrVsp/XsGFD9ejRo8TrF5g7d66SkpJUqVIlSVKjRo3Utm3bQsv1jh8/rrVr1+qvf/2rrr766kLtC5bd2Ww2LVmyRL1791a7du2KvI6zxSbq1aun7t27Fzl+6dicPn1aJ06c0I033qgDBw7o9OnTkqTU1FSdOXNG48aNKzJrdGl/hgwZog0bNhRaNjZ37lzVqVPninu9MjMztWXLFt13332qVq2a/Xh8fLy6du2qlJQU+7H+/fvr2LFjhSo4Llq0SDabTf3795cknTx5UqtWrdLdd99t//t24sQJ/fbbb+revbv27t2rI0eOFOrD8OHDFRwcfNk+/tmIESOUmppa5Ktp06aFzqtVq1ah2a3IyEgNGTJEmzdvVlZWliQpJSVF7du3V6dOneznVaxYUSNGjNChQ4e0c+dOSRf30NWoUUOPPPJIkf78+e9FSZ+Z8PBwhYaGavXq1fr9999L/b4B4EoITgBQSrVr1y52GdmOHTt0xx13qHLlyoqMjFTNmjXtG+sLfji/kj+HjIIfCEvzA9+f2xa0L2h77NgxnTt3Tg0bNixyXnHHirNr1y5t3rxZHTt21L59++xfN910k5YuXars7GxJ//uhtWA5WXGOHz+u7OzsK57jjHr16hV7/Ntvv1WXLl3s+4pq1qxp35tWMDYFQaikPvXv318Wi8UeFk+fPq2lS5dq8ODBVwx8P//8syTZlw9e6tprr9WJEyfsy+duvfVWVa5cWQsWLLCfs2DBArVq1UrXXHONJGnfvn0yDEMTJkxQzZo1C31NnDhR0sVxL83353IaNWqkLl26FPmKjIwsdF7Dhg2LvPeCfhbsJfr5558v+94LnpcujkPjxo1LVQSlpM+MxWLRq6++quXLlys6Olo33HCDXnvtNXuYAwBnsMcJAEqpuCptp06d0o033qjIyEi98MILatCggcLCwpSWlqannnpKNputxOtebibAKMXdIsrStrQKyrU/9thjeuyxx4o8v3jx4mJn4srickHkzwU3ChQ3Nvv379ctt9yiJk2aaOrUqapTp45CQ0OVkpKiN954o1Rjc6mqVauqV69emjt3rp577jktWrRIubm5Lq0+Z7FY1KdPH33yySf65z//qaNHj+rbb7/Vyy+/bD+noN9/+9vfip1lk4qGYn+rMFiav/ePPvqoevfurSVLluiLL77QhAkTNHnyZK1atUqtW7cur64C8CMEJwAog9WrV+u3337Txx9/rBtuuMF+/ODBgx7s1f9ERUUpLCxM+/btK/Jcccf+zDAMffTRR/rLX/6ihx9+uMjzL774oubOnathw4apfv36klSo8tuf1axZU5GRkVc8R/rfDMKpU6dUpUoV+/GC2YnS+Pzzz5Wbm6vPPvus0AzF119/Xei8gqWO27dvL3EWbsiQIbr99tv1ww8/aO7cuaW6r1HdunUlXSxg8We7d+9WjRo1CpUH79+/v2bPnq2VK1dq165dMgzDvkxPkv37bDab1aVLlyu+trsVzH5dGnR/+uknSbIXYKhbt+5l33vB89LFcdiwYYPy8/PLVLr/Ug0aNNDjjz+uxx9/XHv37lWrVq3097//vci92wCgNFiqBwBlUPCb70t/052Xl6d//vOfnupSIcHBwerSpYuWLFmijIwM+/F9+/Zp+fLlJbb/9ttvdejQIQ0bNkx33XVXka/+/fvr66+/VkZGhmrWrKkbbrhBs2bN0uHDhwtdp+D7ExQUpD59+ujzzz/Xjz/+WOT1Cs4rCDNr1661P5eTk2Ov6lfa937pNaWLy+s++OCDQud169ZNlSpV0uTJk4uUFP/zzF2PHj1Uo0YNvfrqq1qzZk2pZptiY2PVqlUrzZ49W6dOnbIf3759u7788ssiN5rt0qWLqlWrpgULFmjBggVq3759oaV2UVFRuummm/Tuu+8qMzOzyOsVVzLdXTIyMvTJJ5/YH2dnZ+vf//63WrVqpZiYGElSz549tXHjRq1fv95+Xk5Ojt577z3FxcXZ90317dtXJ06c0Ntvv13kdRydQT179myRsWzQoIEqVaqk3Nxch64FAAWYcQKAMrj++utVtWpVDR06VGPGjJHJZNJ//vMfly6VK6tJkybpyy+/VMeOHTVy5EhZrVa9/fbbat68ubZs2XLFtnPnzlVwcLCSkpKKff62227TM888o/nz5ys5OVnTpk1Tp06d1KZNG40YMUL16tXToUOHtGzZMvtrvfzyy/ryyy914403asSIEbr22muVmZmphQsXat26dapSpYq6deumq6++Wvfff7+eeOIJBQcHa9asWapZs2aRUHY53bp1U2hoqHr37q0HH3xQf/zxh2bOnKmoqKhCgSMyMlJvvPGGHnjgAV133XUaNGiQqlatqq1bt+rs2bOFwprZbNaAAQP09ttvKzg4WAMHDixVX6ZMmaIePXooMTFR999/v70ceeXKlTVp0qRC55rNZt15552aP3++cnJy9Prrrxe53jvvvKNOnTqpRYsWGj58uOrXr6+jR49q/fr1+vXXX7V169ZS9ety0tLSip2VadCggRITE+2Pr7nmGt1///364YcfFB0drVmzZuno0aOFwum4ceM0b9489ejRQ2PGjFG1atU0e/ZsHTx4UIsXL1ZQ0MXf4Q4ZMkT//ve/lZycrI0bN6pz587KycnRV199pYcffli33357qfv/008/6ZZbbtHdd9+tpk2bKiQkRJ988omOHj2qAQMGlOE7AyCgeaKUHwB4s8uVI2/WrFmx53/77bdGhw4djPDwcKNWrVrGk08+aXzxxRdFylRfrhx5cSWTJRkTJ060P75cOfJRo0YVaVu3bl1j6NChhY6tXLnSaN26tREaGmo0aNDA+Ne//mU8/vjjRlhY2GW+C4aRl5dnVK9e3ejcufNlzzEMw6hXr16h8tPbt2837rjjDqNKlSpGWFiY0bhxY2PChAmF2vz888/GkCFDjJo1axoWi8WoX7++MWrUKCM3N9d+zqZNm4yEhAQjNDTUuPrqq42pU6dethx5UlJSsX377LPPjPj4eCMsLMyIi4szXn31VXvZ60uvUXDu9ddfb4SHhxuRkZFG+/btjXnz5hW55saNGw1JRrdu3a74ffmzr776yujYsaP9+r179zZ27txZ7LmpqamGJMNkMhm//PJLsefs37/fGDJkiBETE2OYzWajdu3aRq9evYxFixbZzyn4fhVX+r04JZUjv/TvVcH3/YsvvjDi4+MNi8ViNGnSxFi4cGGxfb3rrrvsfyfat29vLF26tMh5Z8+eNZ555hmjXr16htlsNmJiYoy77rrL2L9/f6H+lfSZOXHihDFq1CijSZMmRoUKFYzKlSsbCQkJxn//+99SfR8AoDgmw/CiX4sCAMpNnz59tGPHDu3du9fTXfEpW7duVatWrfTvf/9b9957r6e74zFxcXFq3ry5li5d6umuAEC5YI8TAASAc+fOFXq8d+9epaSk6KabbvJMh3zYzJkzVbFiRd15552e7goAoByxxwkAAkD9+vV13333qX79+vr55581ffp0hYaG6sknn/R013zG559/rp07d+q9997T6NGjC1XCAwD4P4ITAASAW2+9VfPmzVNWVpYsFosSExP18ssvq1GjRp7ums945JFHdPToUfXs2VPPP/+8p7sDAChn7HECAAAAgBKwxwkAAAAASkBwAgAAAIASBNweJ5vNpoyMDFWqVEkmk8nT3QEAAADgIYZh6MyZM6pVq5b9htyXE3DBKSMjQ3Xq1PF0NwAAAAB4iV9++UVXXXXVFc8JuOBUqVIlSRe/OZGRkR7ujZSfn68vv/xS3bp1k9ls9nR34AKMqX9iXP0PY+qfGFf/xLj6H28Z0+zsbNWpU8eeEa4k4IJTwfK8yMhIrwlOERERioyM5B8CP8GY+ifG1f8wpv6JcfVPjKv/8bYxLc0WHopDAAAAAEAJCE4AAAAAUAKCEwAAAACUgOAEAAAAACUgOAEAAABACQhOAAAAAFACghMAAAAAlIDgBAAAAAAlIDgBAAAAQAkITgAAAABQAoITAAAAAJSA4AQAAAAAJSA4AQAAAEAJQjzdAQAAAAC+y2oztPHgSWWdPqcTf+Tq5Nk8Zfx+TpJkMpkUWyVMVcJDdercxeMmk0kxkRYFnzKpu82Q2cP9Ly2CEwAAABDgrDZD3+//TesPnJDNkCqHm+1Bp0BxISjj1Dlty8jW+XybE68arLmvrNYrfVvo1uaxrnszbkJwAgAAAPzMlWaBpMIhKO3w71q1+5jyrUa59/PUuXw9NCdNM+5p4/XhieAEAAAA+ICCWaFv9x/XkSsshSvbLJBnPP/5TnVtGqPgIJOnu3JZBCcAAADAA/4chIoLQQUyT5/X1l9PK/eC74QhR2SePq+NB08qsUF1T3flsghOAAAAgIuUtFeoIBwdPZ2rZdsy/TYIOePYmfOe7sIVEZwAAACAUihphujHgye15dfTHtkr5A+iKoV5ugtXRHACAABAQCtNOW1miNwrtnKY2ter5uluXBHBCQAAAH7tSsvnfLGQgj+a2LupVxeGkAhOAAAA8AOXC0csn/NuVSLMeuVO7uMEAAAAuIzVZmjj3hP6dv9xZZw67xX3IUJhlhCTbrqmpsLMwZKKL5duMpkUE2lR8PF9emRAV4VZQj3c69IhOAEAAMBrXFqAoSAcVQoN1opdJv1t41eEo3IQGiz1io9VdOXwy94098+VAmtXDdf1DWqoQ/3qpVpyl5+fr5SUvV6/PO9SBCcAAACUu+KW1l155ihYEqHJGX+eBZKKhqDMU+cdDj+BhuAEAAAAt3E8IKEklmCT4q+qrFpVwl06C4QrIzgBAADAZS5davcDhRlKLcQkta5bVe3iqhYJQRJByBsQnAAAAOCwP98MVpIyT5/X1l9Pc6+j/6+4vUKXzhBln8+XSSYlNqhOGPIBHg9O77zzjqZMmaKsrCy1bNlSb731ltq3b1/sufn5+Zo8ebJmz56tI0eOqHHjxnr11Vd16623lnOvAQAAAsefCzacy7dqzU/HA/reR5ebIWJmyH95NDgtWLBAycnJmjFjhhISEvTmm2+qe/fu2rNnj6Kiooqc/+yzz2rOnDmaOXOmmjRpoi+++EJ33HGHvvvuO7Vu3doD7wAAAMC//HlPUtbp81q2LTNgZpGuVE6bGaLA5tHgNHXqVA0fPlzDhg2TJM2YMUPLli3TrFmzNG7cuCLn/+c//9Ezzzyjnj17SpJGjhypr776Sn//+981Z86ccu07AACAvygIS//+/pDfF2243PI5ZolQEo8Fp7y8PG3atEnjx4+3HwsKClKXLl20fv36Ytvk5uYqLCys0LHw8HCtW7fusq+Tm5ur3Nxc++Ps7GxJF5f95efnl+UtuERBH7yhL3ANxtQ/Ma7+hzH1T4xryaw2QxsPntR3B35T5unzOptn1Td7f9N5P5pRCg2WejaLUVRli7JOn5chk2pXCVdi/WpKqFftisHIZr0gm7UcOxugvOWz6sjrmwzD8MivFDIyMlS7dm199913SkxMtB9/8skntWbNGm3YsKFIm0GDBmnr1q1asmSJGjRooJUrV+r222+X1WotFI4uNWnSJD3//PNFjn/00UeKiIhw3RsCAADwUjZD2nvapHVZ0o5TQbIavj+jEixDTasYql/JUM4F6VS+SVVDpWsqG2pY2RCTRiiNs2fPatCgQTp9+rQiIyOveK7Hi0M44h//+IeGDx+uJk2ayGQyqUGDBho2bJhmzZp12Tbjx49XcnKy/XF2drbq1Kmjbt26lfjNKQ/5+flKTU1V165dZTabPd0duABj6p8YV//DmPonxvWiS2eVNv18SulHsn1yj5I5SPrLNTUVX7uStuzcq/AatVS7akSpZo7g3bzls1qwGq00PBacatSooeDgYB09erTQ8aNHjyomJqbYNjVr1tSSJUt0/vx5/fbbb6pVq5bGjRun+vXrX/Z1LBaLLBZLkeNms9mr/kH1tv6g7BhT/8S4+h/G1D8F0rgWhKSs0+d04o9c/fiz791c9tJ9R5mnzhfZb5Sfn6+Usz+pZ8+WATOugcLTn1VHXttjwSk0NFRt27bVypUr1adPH0mSzWbTypUrNXr06Cu2DQsLU+3atZWfn6/Fixfr7rvvLoceAwAAeA+rzdBbK/fqX+sO6I9c39iUU1JAAryZR5fqJScna+jQoWrXrp3at2+vN998Uzk5OfYqe0OGDFHt2rU1efJkSdKGDRt05MgRtWrVSkeOHNGkSZNks9n05JNPevJtAAAAuFVxJcI/25qhCzbvnVWyBJsUf1Vl1a4aQUCCX/BocOrfv7+OHz+u5557TllZWWrVqpVWrFih6OhoSdLhw4cVFBRkP//8+fN69tlndeDAAVWsWFE9e/bUf/7zH1WpUsVD7wAAAMB9CmaVZqzZ79VV7ywhJrWoXVlXEZLgxzxeHGL06NGXXZq3evXqQo9vvPFG7dy5sxx6BQAAUP4u3a+0bt8JfbrF+2aVzEHSzU2i1C6uumpUsigmMkztKdSAAODx4AQAABDILr357Jqfjut8vvfMLBXsSYqtEiGTTEpsUJ2ZJAQsghMAAIAHeOsyvDBzkG66pqbuTYwjJAGXIDgBAACUg4KZpW/3H9ePh35X2uFTHl+Gx7I7oPQITgAAAG7kTTNLlmCTWtapouvqVaOAA+AgghMAAIALedvMkjlIuuXaaJbeAWVEcAIAAHABb5hZCgmSbmkSpfDQEMqCAy5GcAIAAHDCpTel3XvsD63afUz5Vs/MLFlCTBp5YwM9css1hCTATQhOAAAADvD0zFJIkHRbS0qEA+WN4AQAAFAKBYHpna/3Kd8De5aYVQI8i+AEAABQDE8XebCEmPSXxlFqGFWJWSXACxCcAAAALuHJpXhUwAO8F8EJAAAENE/PLIWFBOkvTaJ0T4e6hCXAixGcAABAQGJmCYAjCE4AACBgWG2GNh48qS93ZGrOhsPlWj6cmSXAtxGcAACA3yuYXfrXugP6I9dabq8bHCR1ZWYJ8AsEJwAA4Lc8VUK8giVYwzvVo3Q44EcITgAAwK/YDGnDwZNauft4uS3HCwmSbm9VS50aRSkmMkzt61UjMAF+huAEAAB8XkFlvNnrD+jr3cHK//7HcnldbkoLBA6CEwAA8EmXFnqY98MvOp9fUBnPvQGGIg9AYCI4AQAAn+KJQg+UDwdAcAIAAD6hvAs9MLME4FIEJwAA4LXK+75LlA8HcDkEJwAA4HXKezke5cMBlITgBAAAvEZ5LsczB5t0T8LV6tYslvLhAEpEcAIAAB5V3svxzMEmjbqJEuIAHENwAgAAHpOSnqlnP92ukzl5bn8tluMBKAuCEwAAKHdWm6Gx8zZr6bZMt75OmDlIA6+rw3I8AGVGcAIAAOXi0iV5//n+Z12wldzGGWaToZubRGtIx3pUxgPgMgQnAADgVuVRIa+g0MMtTWrq+M7v1Suplcxms1teC0BgIjgBAAC3KI8KeX8u9JCfn6+UXW55KQABjuAEAABcprwq5FHoAUB5IzgBAIAyK8/leBR6AOAJBCcAAOA0TyzHAwBPIDgBAACnpKRnKvm/W3TeTeXxWI4HwJsQnAAAQKlZbYa+3/+bXv9ytzb/ctotr/GXxjU04oaGLMcD4FUITgAAoEQFS/JmrNnvthmmMHOQpvZrqZ7xtdxyfQAoC4ITAAAoFhXyAOB/CE4AAKAQKuQBQFEEJwAAIIkKeQBwJQQnAAACGMvxAKB0CE4AAASolPRMPfvpdp3MyXPL9VmOB8CfEJwAAAgwVpuhsfM2a+m2TLdcn+V4APwRwQkAgABRsIfp7VV7dcENK/IsISaNvJHABMA/EZwAAPBzVpuht1ft0zur9ynPDfdgsoSY9PBNDTX65kYEJgB+i+AEAICfcvdNa1mSByCQEJwAAPBDKemZSv7vFrcEJirkAQhEBCcAAPxEQWnx99bu19d7jrv02lTIAxDoCE4AAPgBd5UWZzkeAFxEcAIAwIe5q7Q4y/EAoDCCEwAAPiolPVOPLdisXKvraov/pXENjbihIcvxAOBPCE4AAPgQd+1jCjMHaWq/luoZX8tl1wQAf0JwAgDAR7hjHxM3rQWA0iE4AQDg5dyxj6lNncp6vHsTdahfncAEAKVAcAIAwIu5eh8TS/IAwDkEJwAAvNRLy3Zq5jcHXXa9pBbRmjawLTNMAOAEghMAAF7EajP0/f7fNOWLXdrya7ZLrlmtgln/d3tzZpkAoAwITgAAeImU9Ew9uThdf+RecMn1KC0OAK5DcAIAwAu4clke+5gAwPUITgAAeEjBPZneXbNPq3864ZJrso8JANyD4AQAgAe4+p5M7GMCAPciOAEAUM5cuSyPfUwAUD4ITgAAlBOrzdCYj9K0bHtWma/FPiYAKF8EJwAAyoErb2TLPiYAKH8EJwAA3MhqMzR2/mYtTc8s87UqWoL1Wt94ZpkAwAMITgAAuElKeqaeWLRVOXnWMl3HEmLSwzc11OibGzHLBAAeQnACAMANXFUAomfzaL01iGV5AOBpBCcAAFzIlQUghneO0zNJzVzQKwBAWRGcAABwEVcVgOCeTADgfQhOAACUkasKQNzUuIYe5J5MAOCVCE4AAJSBqwpAsCwPALwbwQkAACe5ogAEN7IFAN9AcAIAwAkvLt2h99cdcrq9JcSkkTc20CO3XMOyPADwAQQnAABKyWoztPHgSb27Zp9W/3TC6esktYjRtIFtCEwA4EMITgAAlEJKeqae/XS7Tubklek693eK04Re7GUCAF9DcAIAoASuupktBSAAwHcRnAAAuIKy7mWSKAABAP6A4AQAwGVQAAIAUIDgBABAMcoamigAAQD+heAEAMAlrDZDY+aladm2LKevQQEIAPA/BCcAAP6/lPRMPbFoq3LyrE5fg9AEAP6J4AQAgFxTOY+qeQDgvwhOAICAV9b9TNUqmPV/tzenah4A+DGCEwAgoL28fLc++O6wU21valxDD97QUO3rVaMIBAD4uSBPd+Cdd95RXFycwsLClJCQoI0bN17x/DfffFONGzdWeHi46tSpo8cee0znz58vp94CAPzJJwdNToem+zvF6cNhCUpsUJ3QBAABwKPBacGCBUpOTtbEiROVlpamli1bqnv37jp27Fix53/00UcaN26cJk6cqF27dun999/XggUL9PTTT5dzzwEAvsxqMzR2/hatznLuv0EKQABA4PFocJo6daqGDx+uYcOGqWnTppoxY4YiIiI0a9asYs//7rvv1LFjRw0aNEhxcXHq1q2bBg4cWOIsFQAA0sXA9GbqT2o6YblSdhyT5PhM0fDOhCYACEQe2+OUl5enTZs2afz48fZjQUFB6tKli9avX19sm+uvv15z5szRxo0b1b59ex04cEApKSm69957L/s6ubm5ys3NtT/Ozs6WJOXn5ys/P99F78Z5BX3whr7ANRhT/8S4+r7l27P05OLtOn/B5lT7CqHBmtynmXq0iOHvgRfjs+qfGFf/4y1j6sjreyw4nThxQlarVdHR0YWOR0dHa/fu3cW2GTRokE6cOKFOnTrJMAxduHBBDz300BWX6k2ePFnPP/98keNffvmlIiIiyvYmXCg1NdXTXYCLMab+iXH1TUsOmfR1ZpCcmWGSDLWqZtPQay7I+CVNKb+4undwBz6r/olx9T+eHtOzZ8+W+lyfqqq3evVqvfzyy/rnP/+phIQE7du3T2PHjtWLL76oCRMmFNtm/PjxSk5Otj/Ozs5WnTp11K1bN0VGRpZX1y8rPz9fqamp6tq1q8xms6e7AxdgTP0T4+qbrDZDyf/dqq8zi987WxrDrq+rp3s0cWGv4E58Vv0T4+p/vGVMC1ajlYbHglONGjUUHByso0ePFjp+9OhRxcTEFNtmwoQJuvfee/XAAw9Iklq0aKGcnByNGDFCzzzzjIKCim7ZslgsslgsRY6bzWav+uB5W39Qdoypf2JcfUdKeqaeWLRVOXlWp69BEQjfxWfVPzGu/sfTY+rIa3usOERoaKjatm2rlStX2o/ZbDatXLlSiYmJxbY5e/ZskXAUHBwsSTIMw32dBQD4lJeW7dTDH6URmgAALuPRpXrJyckaOnSo2rVrp/bt2+vNN99UTk6Ohg0bJkkaMmSIateurcmTJ0uSevfuralTp6p169b2pXoTJkxQ79697QEKABDYXly6Q++vO1SmawzvHKdnkghNAID/8Whw6t+/v44fP67nnntOWVlZatWqlVasWGEvGHH48OFCM0zPPvusTCaTnn32WR05ckQ1a9ZU79699dJLL3nqLQAAvEhZQ1NFS7Be6xuvnvG1XNcpAIBf8HhxiNGjR2v06NHFPrd69epCj0NCQjRx4kRNnDixHHoGAPAlZQ1NveNj9OaANgoOcqbyHgDA33k8OAEAUBZWm6Ex89K0bFuWU+3DQoI09e6WzDIBAK6I4AQA8FllrZzXqqpV8x/tqjBLqIt7BgDwNwQnAIBPemnZTs385qBTbStagvXy7c1k/JLG0jwAQKkQnAAAPqcs+5mSWsRo2sA2slkvKOUX1/YLAOC/CE4AAJ9SltB06b2ZbM7f4gkAEIA8dgNcAAAc5arQBACAo5hxAgB4vbJWziM0AQDKiuAEAPBqK7Zn6qnF6Tp97oJT7Yd3jtMzSYQmAEDZEJwAAF5rxfZMPTQnzam2FS3Beq1vPPdnAgC4BMEJAOCVrDZD4z7e5lTbgsp5lBoHALgKwQkA4JXGzEvTqbP5DrdjPxMAwB2oqgcA8DovLt3hVCEIQhMAwF2YcQIAeI2yVM8jNAEA3IngBADwCinpmXpi0Vbl5Dl+Z1oq5wEA3I3gBADwuJeW7dTMbw463C7MHKSp/VpSOQ8A4HYEJwCAR724dIfeX3fI4XZh5iClT+yu0BC26wIA3I//bQAAHuNsaJKkqf1aEZoAAOWG/3EAAB5RltA0vHM99YyPdW2HAAC4ApbqAQDKVVkq50kXq+c9k9TUxb0CAODKCE4AgHKzYnumnlqcrtPnLjjVnup5AABPITgBAMrFiu2ZemhOmlNtK1qC9VrfeKrnAQA8huAEAHA7q83QuI+3OdU2qUWMpg1so+Agk4t7BQBA6RGcAABuN2Zemk6dzXe43f2d4jShF0vzAACeR1U9AIBbvbh0h1OFIAhNAABvQnACALiNsyXHCU0AAG/DUj0AgMuVpeQ4lfMAAN6I4AQAcKmU9Ew9sWircvKsDrULMwdpar+WVM4DAHglghMAwGUmp+zUu2sPOtwuzByk9IndFRrCCnIAgHfifygAgEukpGc4FZokaWq/VoQmAIBX438pAECZWW2Gnlic7lTb4Z3rqWd8rIt7BACAaxGcAABlNmZemnJyHdvTJF2snvdMUlM39AgAANciOAEAnGa1GRo1dxP3aQIA+D2KQwAAnOJs9TyJkuMAAN9DcAIAOOylZTs18xvHC0FUtATrtb7xlBwHAPgcghMAwCEvLduhmd8ccrhdh/rVNPeBDgoOMrm+UwAAuBl7nAAApZaSnuFUaKoQGkxoAgD4NIITAKBUylJyfMpdLQlNAACfRnACAJSKsyXHuU8TAMAfEJwAAFdUlpLjF6vncZ8mAIDvozgEAOCyVmzP1FOL03X63AWH2lE9DwDgbwhOAIBirdieqYfmpDncLqlFjKYNbMOeJgCAXyE4AQCKsNoMjft4m8PtklrE6J3Bbd3QIwAAPIs9TgCAIsbMS9Ops/kOtakQGqxpA9u4qUcAAHgWwQkAUMiLS3c4VQiCkuMAAH9GcAIA2L24dIfeX3fI4XaUHAcA+DuCEwBAkvTSMmdDEyXHAQD+j+IQAAAt3ZKhmd8ccqhNmDlIU/u1pOQ4ACAgEJwAIMAt3ZKh0fM3O9QmzByk9IndFRrCwgUAQGAgOAFAAHtp2U7N/Oagw+2m9mtFaAIABBSCEwAEKApBAABQevy6EAACkLOFIO7vRCEIAEBgIjgBQIBJSXe8EIR0MTRN6NXM9R0CAMAHsFQPAAJI3gWbkhdudbjdxZLjhCYAQOAiOAFAgEhJz1Tywi06n28rdRuTpLcGtFavVpQcBwAENoITAASAySk79e5ax6vnEZoAALiIPU4A4OdS0jOcCk3DO9cjNAEA8P8RnADAj1lthp5YnO5wO6rnAQBQGMEJAPzYmHlpysm1OtQmqUUM1fMAAPgTghMA+KmXlu3Qsm1ZDrWpHB6iaQPbuKlHAAD4LoITAPghZ+/V9GrfeAUHmVzfIQAAfBzBCQD8jDP3aqoaYdaMe9ro1uaxbuoVAAC+jXLkAOBHnLlXU4f61TT3gQ7MNAEAcAUEJwDwE87cq6lCaDChCQCAUmCpHgD4AWfv1TTlrpaEJgAASoHgBAA+ztl7NQ3vXE8949nTBABAaTgcnOLi4vTCCy/o8OHD7ugPAMBBzt6riRvcAgBQeg4Hp0cffVQff/yx6tevr65du2r+/PnKzc11R98AACXgXk0AAJQPp4LTli1btHHjRl177bV65JFHFBsbq9GjRystLc0dfQQAFIN7NQEAUH6c3uPUpk0bTZs2TRkZGZo4caL+9a9/6brrrlOrVq00a9YsGYbhyn4CAC7BvZoAAChfTpcjz8/P1yeffKIPPvhAqamp6tChg+6//379+uuvevrpp/XVV1/po48+cmVfAQCSVmzP1OMLt3KvJgAAypHDwSktLU0ffPCB5s2bp6CgIA0ZMkRvvPGGmjRpYj/njjvu0HXXXefSjgIALoamh+Y4tiyaezUBAFB2Dgen6667Tl27dtX06dPVp08fmc3mIufUq1dPAwYMcEkHAQAXWW2Gxn28zeF23KsJAICyczg4HThwQHXr1r3iORUqVNAHH3zgdKcAAEWNmZemU2fzHWrDvZoAAHANh4tDHDt2TBs2bChyfMOGDfrxxx9d0ikAQGHOlB3nXk0AALiOw8Fp1KhR+uWXX4ocP3LkiEaNGuWSTgEA/seZsuPcqwkAANdyODjt3LlTbdoU/c+4devW2rlzp0s6BQC4yGoz9MTidIfbca8mAABcy+HgZLFYdPTo0SLHMzMzFRLidHVzAEAxHp2fppxca6nPr2gJ4V5NAAC4gcPBqVu3bho/frxOnz5tP3bq1Ck9/fTT6tq1q0s7BwCBbOmWDH2eXvp9TWHmIKVN6EpoAgDADRyeInr99dd1ww03qG7dumrdurUkacuWLYqOjtZ//vMfl3cQAALR0i0ZGj1/s0NtpvZrpdAQh38fBgAASsHh4FS7dm2lp6dr7ty52rp1q8LDwzVs2DANHDiw2Hs6AQAc89KynZr5zUGH2lB2HAAA93JqU1KFChU0YsQIV/cFAALeS8t2OFxBj7LjAAC4n9PVHHbu3KnDhw8rLy+v0PHbbrutzJ0CgEDkTNnxCqHBlB0HAKAcOBycDhw4oDvuuEPbtm2TyWSSYRiSJJPpYtlbq7X01Z8AABc5W3Z8yl0tKTsOAEA5cHgX8dixY1WvXj0dO3ZMERER2rFjh9auXat27dpp9erVTnXinXfeUVxcnMLCwpSQkKCNGzde9tybbrpJJpOpyFdSUpJTrw0A3sDRsuOS9OAN7GsCAKC8ODzjtH79eq1atUo1atRQUFCQgoKC1KlTJ02ePFljxozR5s2OVYFasGCBkpOTNWPGDCUkJOjNN99U9+7dtWfPHkVFRRU5/+OPPy60PPC3335Ty5Yt1a9fP0ffCgB4BUfLjpskvTWgtXq1quW+TgEAgEIcDk5Wq1WVKlWSJNWoUUMZGRlq3Lix6tatqz179jjcgalTp2r48OEaNmyYJGnGjBlatmyZZs2apXHjxhU5v1q1aoUez58/XxEREZcNTrm5ucrNzbU/zs7OliTl5+crPz/f4f66WkEfvKEvcA3G1D+5a1yXpWfq0YXbHGrzRr8W6t6sJn/HyojPqn9iXP0T4+p/vGVMHXl9k1GwSamUOnfurMcff1x9+vTRoEGD9Pvvv+vZZ5/Ve++9p02bNmn79u2lvlZeXp4iIiK0aNEi9enTx3586NChOnXqlD799NMSr9GiRQslJibqvffeK/b5SZMm6fnnny9y/KOPPlJERESp+woArvbpIZNWZQbp4hxSaRj6S6xNfeIc+mcbAABcxtmzZzVo0CCdPn1akZGRVzzX4RmnZ599Vjk5OZKkF154Qb169VLnzp1VvXp1LViwwKFrnThxQlarVdHR0YWOR0dHa/fu3SW237hxo7Zv367333//sueMHz9eycnJ9sfZ2dmqU6eOunXrVuI3pzzk5+crNTVVXbt25T5YfoIx9U+uHtfl27K0ar1jxSB6NovWPwa0KvNr4yI+q/6JcfVPjKv/8ZYxLViNVhoOB6fu3bvb/9ywYUPt3r1bJ0+eVNWqVe2V9crL+++/rxYtWqh9+/aXPcdischisRQ5bjabveqD5239Qdkxpv7JFeNqtRka/+kOh9pUCA3WW4PbUUHPDfis+ifG1T8xrv7H02PqyGs7VFUvPz9fISEhRZbjVatWzanQVKNGDQUHB+vo0aOFjh89elQxMTFXbJuTk6P58+fr/vvvd/h1AcCTxsxzvIIeZccBAPAsh4KT2WzW1Vdf7bJ7NYWGhqpt27ZauXKl/ZjNZtPKlSuVmJh4xbYLFy5Ubm6u7rnnHpf0BQDKw0vLdmjZttJX0JMoOw4AgDdw+D5OzzzzjJ5++mmdPHnSJR1ITk7WzJkzNXv2bO3atUsjR45UTk6OvcrekCFDNH78+CLt3n//ffXp00fVq1d3ST8AwN1S0jM085tDpT7fJOntAa01vmdTt/UJAACUjsN7nN5++23t27dPtWrVUt26dVWhQoVCz6elpTl0vf79++v48eN67rnnlJWVpVatWmnFihX2ghGHDx9WUFDhfLdnzx6tW7dOX375paPdBwCPyLtgU/LCrQ614V5NAAB4D4eD06Vlw11l9OjRGj16dLHPrV69usixxo0by8Eq6gDgMSu2Z+rxhVt1Pt9W6ja94mMJTQAAeBGHg9PEiRPd0Q8A8EsrtmfqoTmOzcRXCA3WPwa0dlOPAACAMxze4wQAKB2rzdC4j7c53I4KegAAeB+HZ5yCgoKuWHrcVRX3AMDXjZmXplNn8x1qM7wzFfQAAPBGDgenTz75pNDj/Px8bd68WbNnz9bzzz/vso4BgC9zpux4UosYPZNEBT0AALyRw8Hp9ttvL3LsrrvuUrNmzbRgwQJuSAsg4DladlySKoeHaNrANu7pEAAAKDOX7XHq0KFDoRvZAkAgstoMPbE43eF2r/aNZ18TAABezCXB6dy5c5o2bZpq167tissBgM96dH6acnJLv9ezoiVEM+5po1ubs68JAABv5vBSvapVqxYqDmEYhs6cOaOIiAjNmTPHpZ0DAF+ydEuGPk8v/b6mMHOQ0iZ0VWgIBU4BAPB2DgenN954o1BwCgoKUs2aNZWQkKCqVau6tHMA4CuWbsnQ6PmbHWoztV8rQhMAAD7C4eB03333uaEbAOC7Jqfs1LtrDzrUhrLjAAD4Fod/1fnBBx9o4cKFRY4vXLhQs2fPdkmnAMBXpKRnOByaKDsOAIDvcTg4TZ48WTVq1ChyPCoqSi+//LJLOgUAvsCZCnoVQoMpOw4AgA9yODgdPnxY9erVK3K8bt26Onz4sEs6BQC+YMw8xyroSdKUu1pSdhwAAB/kcHCKiopSenrR37Bu3bpV1atXd0mnAMDbvbRsh5ZtK30FPUl68Ab2NQEA4KscLg4xcOBAjRkzRpUqVdINN9wgSVqzZo3Gjh2rAQMGuLyDAOBtlm7J0MxvDpX6fJOktwa0Vq9WtdzWJwAA4F4OB6cXX3xRhw4d0i233KKQkIvNbTabhgwZwh4nAH5vWXqmHl24zaE2hCYAAHyfw8EpNDRUCxYs0P/93/9py5YtCg8PV4sWLVS3bl139A8AvManh0xatd6x0NQrPpbQBACAH3A4OBVo1KiRGjVq5Mq+AIDXWr4tS6syHdsWWiE0WP8Y0NpNPQIAAOXJ4eIQffv21auvvlrk+GuvvaZ+/fq5pFMA4E2sNkPjl+zQxd1KpUcFPQAA/IfDwWnt2rXq2bNnkeM9evTQ2rVrXdIpAPAmj85PU06eY2XHh3emgh4AAP7E4eD0xx9/KDQ0tMhxs9ms7Oxsl3QKALxFSnqGPk93rOz48M5xeiapqZt6BAAAPMHh4NSiRQstWLCgyPH58+eraVN+UADgP6w2Q08sLnrfussxSXp7QGs9k9TMfZ0CAAAe4XBxiAkTJujOO+/U/v37dfPNN0uSVq5cqY8++kiLFi1yeQcBwBOsNkOD//W9cnJLv0SPsuMAAPgvh4NT7969tWTJEr388statGiRwsPD1bJlS61atUrVqlVzRx8BoFyt2J6ppxan6/S5C6VuQ9lxAAD8m1PlyJOSkpSUlCRJys7O1rx58/S3v/1NmzZtktXq2AZqAPAmK7Zn6qE5aQ61oew4AAD+z+E9TgXWrl2roUOHqlatWvr73/+um2++Wd9//70r+wYA5cpqMzTuY8ducCtRdhwAgEDg0IxTVlaWPvzwQ73//vvKzs7W3XffrdzcXC1ZsoTCEAB83qPz03TqbL5DbXrFx1J2HACAAFDqGafevXurcePGSk9P15tvvqmMjAy99dZb7uwbAJQbZ8qOs0QPAIDAUeoZp+XLl2vMmDEaOXKkGjVq5M4+AUC5crTseAGW6AEAEDhKPeO0bt06nTlzRm3btlVCQoLefvttnThxwp19A4By8ej8NIfKjkvSgzfUY4keAAABpNTBqUOHDpo5c6YyMzP14IMPav78+apVq5ZsNptSU1N15swZd/YTANzC0SV6YeYg/XNQa43vyb5OAAACicNV9SpUqKC//vWvWrdunbZt26bHH39cr7zyiqKionTbbbe5o48A4BZ5F2xKXri11OebTYY2PX2zesZzvyYAAAKN0+XIJalx48Z67bXX9Ouvv2revHmu6hMAuF1Keqbin/9C5/NtpW5zTyObQkPK9M8mAADwUU7dAPfPgoOD1adPH/Xp08cVlwMAt5qcslPvrj3oUJuk5tFqVemIm3oEAAC8Hb86BRBQUtIzHA5NFUKD9fd+8W7qEQAA8AUEJwABg7LjAADAWQQnAAHDmbLjveJjKTsOAAAITgACg6NlxyWpcniI/jGgtZt6BAAAfAnBCYDfc7TseIFX+8azRA8AAEgiOAHwcyu2Z6r1i186VHa8aoRZM+5po1ubs0QPAABc5JJy5ADgjVZsz9RDc9IcatOhfjXNfaADM00AAKAQZpwA+CWrzdC4j7c51KZCaDChCQAAFIvgBMAvjZmXplNn8x1qQ9lxAABwOQQnAH7npWU7tGybYxX0KDsOAACuhOAEwK+kpGdo5jeHHGpD2XEAAFASghMAv2G1GXpicbrD7Sg7DgAASkJwAuA3Hp2fppxca6nPr2gJoew4AAAoFcqRA/ALS7dk6PP00u9rCjMHKW1CV4WG8PsjAABQMn5iAODzlm7J0Oj5mx1qM7VfK0ITAAAoNWacAPi0ySk79e7agw61Gd65HhX0AACAQ/h1KwCflZKe4XBoSmoRo2eSmrqpRwAAwF8RnAD4JGcq6FUIDda0gW3c1CMAAODPCE4AfNKYeY5V0JOkKXe1pOw4AABwCsEJgM95adkOLdtW+gp6kvTgDexrAgAAzqM4BACfkpKeoZnfHCr1+SZJbw1orV6tarmtTwAAwP8x4wTAZ+RdsCl54VaH2hCaAACAKxCcAPiElPRMxT//hc7n20rdpld8LKEJAAC4BEv1AHg9Z+7VVCE0WP8Y0NpNPQIAAIGGGScAXs2ZezVJVNADAACuRXAC4LWcuVeTJA3vTAU9AADgWgQnAF7LmXs1JbWI0TNJTd3UIwAAEKgITgC8kjP3aqocHqJpA9u4qUcAACCQEZwAeJ2lWxy7V1OBV/vGs68JAAC4BcEJgFdZuiVDo+dvdqhN1QizZtzTRrc2Z18TAABwD8qRA/AazpQd71C/muY+0IGZJgAA4FbMOAHwCs6UHa8QGkxoAgAA5YLgBMDjnC07zr2aAABAeSE4AfA4Z8qOc68mAABQnghOADzKmbLjwzvHca8mAABQrigOAcBjUtIdKztukvTWgNbq1aqW2/oEAABQHGacAHhE3gWbkhdudagNoQkAAHgKwQlAuUtJz1T881/ofL6t1G16xccSmgAAgMewVA9AuXpp2U7N/MbxsuP/GNDaTT0CAAAoGcEJQLl5adkOh/Y0FaDsOAAA8DSW6gEoF44WgihA2XEAAOANCE4A3M7ZG9wmtYih7DgAAPAKBCcAbufMDW4rh4do2sA2buoRAACAYwhOANzKmRvcStKrfePZ1wQAALwGwQmA2yzd4vi+pqoRZs24p41ubc6+JgAA4D2oqgfALZZuydDo+ZsdapPUIkbTBrZhpgkAAHgdghMAl3PmXk1JLWL0zuC2buoRAABA2RCcALjUi0t36P11hxxqUyE0mEIQAADAq3l8j9M777yjuLg4hYWFKSEhQRs3brzi+adOndKoUaMUGxsri8Wia665RikpKeXUWwBX8tIyx0OTxA1uAQCA9/PojNOCBQuUnJysGTNmKCEhQW+++aa6d++uPXv2KCoqqsj5eXl56tq1q6KiorRo0SLVrl1bP//8s6pUqVL+nQdQCDe4BQAA/syjwWnq1KkaPny4hg0bJkmaMWOGli1bplmzZmncuHFFzp81a5ZOnjyp7777TmazWZIUFxdXnl0GUIy8CzYlL9zqcLvhneO4wS0AAPAJHgtOeXl52rRpk8aPH28/FhQUpC5dumj9+vXFtvnss8+UmJioUaNG6dNPP1XNmjU1aNAgPfXUUwoODi62TW5urnJzc+2Ps7OzJUn5+fnKz8934TtyTkEfvKEvcI1AG9Pl27P05OLtOn/B5lC7N/u1UFJ8rM98nwJtXAMBY+qfGFf/xLj6H28ZU0de32PB6cSJE7JarYqOji50PDo6Wrt37y62zYEDB7Rq1SoNHjxYKSkp2rdvnx5++GHl5+dr4sSJxbaZPHmynn/++SLHv/zyS0VERJT9jbhIamqqp7sAFwuEMV1yyKSvM4MkObI/ydDQRjaZft2slF8dK1fuDQJhXAMNY+qfGFf/xLj6H0+P6dmzZ0t9rk9V1bPZbIqKitJ7772n4OBgtW3bVkeOHNGUKVMuG5zGjx+v5ORk++Ps7GzVqVNH3bp1U2RkZHl1/bLy8/OVmpqqrl272pcfwrcFyphOXr5bX2cedrjd/R3jNO7Wxm7okXsFyrgGEsbUPzGu/olx9T/eMqYFq9FKw2PBqUaNGgoODtbRo0cLHT969KhiYmKKbRMbGyuz2VxoWd61116rrKws5eXlKTQ0tEgbi8Uii8VS5LjZbPaqD5639Qdl589jmpKeoVnfORGaOsVpQq9mbuhR+fHncQ1UjKl/Ylz9E+Pqfzw9po68tsfKkYeGhqpt27ZauXKl/ZjNZtPKlSuVmJhYbJuOHTtq3759stn+t5fip59+UmxsbLGhCYDrWW2Gnlic7nC7pBYxPh+aAABA4PLofZySk5M1c+ZMzZ49W7t27dLIkSOVk5Njr7I3ZMiQQsUjRo4cqZMnT2rs2LH66aeftGzZMr388ssaNWqUp94CEHDGzEtTTq7VoTaVw0O4wS0AAPBpHt3j1L9/fx0/flzPPfecsrKy1KpVK61YscJeMOLw4cMKCvpftqtTp46++OILPfbYY4qPj1ft2rU1duxYPfXUU556C0DAsNoMjZmXpmXbshxu+2rfeG5wCwAAfJrHi0OMHj1ao0ePLva51atXFzmWmJio77//3s29AnCplPRMPbFoq3LyHJtpqhph1uQ7W+jW5tzgFgAA+DaPBycA3m1yyk69u/agw+2SWsRo2sA2zDQBAAC/QHACcFkp6RlOh6Z3Brd1Q48AAAA8w6PFIQB4L2er51UIDaYQBAAA8DsEJwDFcqZ6niRNuasly/MAAIDfITgBKOLFpTucqp43vHM99YynEAQAAPA/7HECYFeWkuPDO8fpmaSmbugVAACA5xGcAEiSVmzP1FOL03X63AWH2lW0BOu1vvHqGV/LTT0DAADwPIITAK3YnqmH5qQ53K5D/Wqa+0AH9jQBAAC/xx4nIMBZbYbGfbzN4XYVQoMJTQAAIGAQnIAAN2Zemk6dzXe4HdXzAABAICE4AQGM6nkAAAClwx4nIACVpXre/Z2ongcAAAIPwQkIMCnpmXpi0Vbl5Dl+c9uLJcebuaFXAAAA3o3gBASQl5bt1MxvDjrcLswcpKn9WlJyHAAABCyCExAgXly6Q++vO+RwuzBzkNIndldoCFsiAQBA4OInISAAvLTMudAkSVP7tSI0AQCAgMdPQ4CfS0nP0MxvDjnVlup5AAAAFxGcAD9mtRl6YnG6U22pngcAAPA/7HEC/JTVZmjwv75XTi7V8wAAAMqK4AT4IWdLjle0BOu1vvFUzwMAAPgTghPgZ5wtOZ7UIkbTBrZRcJDJDb0CAADwbQQnwI84W3L8/k5xmtCLpXkAAACXQ3EIwE84G5qSWsQQmgAAAEpAcAL8gLOhqUJosKYNbOP6DgEAAPgZluoBPsxqMzRmXpqWbctyqv2Uu1qypwkAAKAUCE6Aj3K2cl6BB2/g5rYAAAClRXACfNDklJ16d63jlfMkSo4DAAA4g+AE+JiU9AynQxMlxwEAAJxDcAJ8iNVm6InF6U61peQ4AACA86iqB/iQMfPSlJPr+J4mQhMAAEDZEJwAH2C1GRo1d5NT1fMITQAAAGXHUj3Ay5Wlet7wznF6JonQBAAAUFYEJ8CLvbRsp2Z+43ghCCrnAQAAuBbBCfBSLy7doffXHXK4XYf61TT3gQ5UzgMAAHAh9jgBXsjZ0FQhNJjQBAAA4AYEJ8DLOBuaJGnKXS0JTQAAAG7AUj3AS1hthsbMS3Oqcp4kDe9cTz3jY13cKwAAAEgEJ8ArlKVynlRQPa+pi3sFAACAAgQnwMOcrZwnUT0PAACgvBCcAA8qy36mpBYxmjawDXuaAAAAygHBCfCQsoSm+zvFaUIvbmwLAABQXqiqB3gAoQkAAMC3MOMElBOrzdD3+3/TlC92acuv2U5dg9AEAADgGQQnoBykpGfqycXp+iP3gtPXuFg5j9AEAADgCQQnwM3KUjVPonIeAACANyA4AW5Ulr1MEpXzAAAAvAXBCXADmyGNnb9FKTuOOX0N9jMBAAB4D4IT4GLLt2dp3IZg5RqEJgAAAH9BcAJc6H/7mZxfWkdoAgAA8D4EJ8BFyrqfSaJyHgAAgLciOAEuUNbQROU8AAAA70ZwApxktRnaePCk3l2zT6t/OuHUNSwhJj18U0ONvrkRlfMAAAC8GMEJcEJKeqae/XS7TubkOX2Nns2j9dagtgQmAAAAH0BwAhxU1hvaSuxlAgAA8DUEJ8AB7GUCAAAITAQnoJTKGpqSWsRo2sA2LM0DAADwQQQnoBTKGpq4NxMAAIBvIzgBV2C1GRozL03LtmU5fQ1CEwAAgO8jOAHFsNoMvbVyr6av3qdcq+H0dQhNAAAA/oHgBPxJSnqmkv+7Recv2MpwFUN/vb4uoQkAAMBPEJyAS7ii1Hi1CmbdVuu8xvdo4qJeAQAAwNMIToBcs5fppsY19OANDdX6qkr6YsVyF/YOAAAAnkZwQkBzx16m/Px8V3UPAAAAXoLghIDlmr1MFIAAAAAIBAQnBCRX7GWSpOGd4/RMEqEJAADA3xGcEDCsNkMbD57Uu2v2afVPJ8p0rYqWYL3WN14942u5qHcAAADwZgQnBISU9Ew9++l2nczJK/O1esfH6M0BbRQcZHJBzwAAAOALCE7we65alhdmDtLUfi2ZZQIAAAhABCf4LavN0JiP0rRsu/MlxgsktYjWtIFtmWUCAAAIUAQn+KWU9Ew9tmBzmUqMS+xlAgAAwEUEJ/gVq83Q2PmbtTQ9s8zXYi8TAAAAChCc4BdcdSNbib1MAAAAKIrgBJ/nqhvZSlLP5tF6axB7mQAAAFAYwQk+zVUV8yRuZgsAAIDLIzjB51hthr7f/5umfLFLW37NLvP1qlUw6/9ub87SPAAAAFwWwQk+JSU9U08uTtcfuRfKfK2bGtfQgzc0VPt61ViaBwAAgCsiOMEnWG2Gxs7brKXbyl4tT2JZHgAAABxDcILXc9U9mSQq5gEAAMA5BCd4LVfek8kSYtLIGxvokVuuYVkeAAAAHEZwgtdx5T2ZJG5kCwAAgLIjOMGruPKeTCzLAwAAgKsQnOAVXF38IalFtKYN5Ea2AAAAcA2CEzzKajP09qp9evvrvcp3wbK8ipZgvdY3nlkmAAAAuFSQpzsgSe+8847i4uIUFhamhIQEbdy48bLnfvjhhzKZTIW+wsLCyrG3cAWrzdCbqT+p2XMr9MZXP5U5NFlCTHqsSyNtndid0AQAAACX8/iM04IFC5ScnKwZM2YoISFBb775prp37649e/YoKiqq2DaRkZHas2eP/bHJxHIsX+LKfUwSy/IAAADgfh4PTlOnTtXw4cM1bNgwSdKMGTO0bNkyzZo1S+PGjSu2jclkUkxMTKmun5ubq9zcXPvj7OxsSVJ+fr7y8/PL2PuyK+iDN/TFnaw2Qz/+/Lv+te6gVv/0m0uuGRYSpNfubK4eLWJks16QzeqSy5ZZoIxpoGFc/Q9j6p8YV//EuPofbxlTR17fZBhG2TeWOCkvL08RERFatGiR+vTpYz8+dOhQnTp1Sp9++mmRNh9++KEeeOAB1a5dWzabTW3atNHLL7+sZs2aFfsakyZN0vPPP1/k+EcffaSIiAiXvRcUz2ZIK34xaXVmkHJtrpkRMpsM3VzLplvrGGKSCQAAAM46e/asBg0apNOnTysyMvKK53p0xunEiROyWq2Kjo4udDw6Olq7d+8utk3jxo01a9YsxcfH6/Tp03r99dd1/fXXa8eOHbrqqquKnD9+/HglJyfbH2dnZ6tOnTrq1q1bid+c8pCfn6/U1FR17dpVZrPZ091xqeXbszR+8XaXLcmTpJ7NozW1X7xXL8vz5zENZIyr/2FM/RPj6p8YV//jLWNasBqtNDy+VM9RiYmJSkxMtD++/vrrde211+rdd9/Viy++WOR8i8Uii8VS5LjZbPaqD5639acsXF1aXPLNezL505jifxhX/8OY+ifG1T8xrv7H02PqyGt7NDjVqFFDwcHBOnr0aKHjR48eLfUeJrPZrNatW2vfvn3u6CIc4OrS4gUo/gAAAABP82g58tDQULVt21YrV660H7PZbFq5cmWhWaUrsVqt2rZtm2JjY93VTZTA1aXFC1S0BOufg1rrncHtCE0AAADwKI8v1UtOTtbQoUPVrl07tW/fXm+++aZycnLsVfaGDBmi2rVra/LkyZKkF154QR06dFDDhg116tQpTZkyRT///LMeeOABT76NgGS1GXpr5V698/U+5dtcN8PUpk5lPd69iTrUr05gAgAAgFfweHDq37+/jh8/rueee05ZWVlq1aqVVqxYYS8YcfjwYQUF/W9i7Pfff9fw4cOVlZWlqlWrqm3btvruu+/UtGlTT72FgOTqezFJvrmPCQAAAIHB48FJkkaPHq3Ro0cX+9zq1asLPX7jjTf0xhtvlEOv8GdWm6Hv9/+m17/crc2/nHbptdnHBAAAAG/mFcEJ3q1gSd6MNftdOsMkSdUqmPV/tzdnlgkAAABejeCEK3LHkjxzsEn3JFytbs1i1b5eNWaZAAAA4PUITiiCJXkAAABAYQQn2LlzSV5FS7Be6xvPkjwAAAD4JIIT3FZWXKK0OAAAAPwDwSlAFSzHm7PhkL7aeczlgYnS4gAAAPAnBKcA487leNLFwg+jbmqgR265hhkmAAAA+A2CU4Bw53I8SbKEmDTyRgITAAAA/BPByY+5ezmedDEwPXxTQ42+uRGBCQAAAH6L4OSH3L0cT2JJHgAAAAILwcmPuHs5nsSSPAAAAAQmgpOPK4/leBJL8gAAABDYCE4+qjyW40ksyQMAAAAkgpPPKJhZWn/ghPYe+0Ordh9TvtU9s0sSS/IAAACASxGcvFx5zSxJkjlI6tI0Rvd0qKsO9asTmAAAAID/j+Dkpcqj0EMBluMBAAAAV0Zw8iLlVeihAMvxAAAAgNIhOHmY1WZozymTls3brK/3nHDrviWJ5XgAAACAMwhOHpSSnqknF23VH3nBko679bVYjgcAAAA4j+DkIZNTdurdtQfd/josxwMAAADKjuDkASnpGW4NTSzHAwAAAFyL4FTOrDZDz3663S3XZjkeAAAA4B4Ep3K28eBJnczJd+k1K1iCNbxTPQITAAAA4CYEp3J27Mz5Ml8jJEi6vVUtdWoUpZjIMLWvV43ABAAAALgRwamcRVUKc7othR4AAAAAzyA4lbP29aoptnKYMk+XbuaJQg8AAACA5xGcyllwkEkTezfVyDlputKtbpldAgAAALwHwckDbm0eq+n3tNHzn+8sNPMUZg7STdfU1L2JccwuAQAAAF6E4OQhtzaPVdemMVq/75i+/GaDunVOUGLDKMISAAAA4IUITh4UHGRSQr1q+m2XoQQq4wEAAABeK8jTHQAAAAAAb0dwAgAAAIASEJwAAAAAoAQEJwAAAAAoAcEJAAAAAEpAcAIAAACAEhCcAAAAAKAEBCcAAAAAKAHBCQAAAABKQHACAAAAgBIQnAAAAACgBAQnAAAAACgBwQkAAAAAShDi6Q6UN8MwJEnZ2dke7slF+fn5Onv2rLKzs2U2mz3dHbgAY+qfGFf/w5j6J8bVPzGu/sdbxrQgExRkhCsJuOB05swZSVKdOnU83BMAAAAA3uDMmTOqXLnyFc8xGaWJV37EZrMpIyNDlSpVkslk8nR3lJ2drTp16uiXX35RZGSkp7sDF2BM/RPj6n8YU//EuPonxtX/eMuYGoahM2fOqFatWgoKuvIupoCbcQoKCtJVV13l6W4UERkZyT8EfoYx9U+Mq/9hTP0T4+qfGFf/4w1jWtJMUwGKQwAAAABACQhOAAAAAFACgpOHWSwWTZw4URaLxdNdgYswpv6JcfU/jKl/Ylz9E+Pqf3xxTAOuOAQAAAAAOIoZJwAAAAAoAcEJAAAAAEpAcAIAAACAEhCcAAAAAKAEBCcPeueddxQXF6ewsDAlJCRo48aNnu4SrmDt2rXq3bu3atWqJZPJpCVLlhR63jAMPffcc4qNjVV4eLi6dOmivXv3Fjrn5MmTGjx4sCIjI1WlShXdf//9+uOPP8rxXeBSkydP1nXXXadKlSopKipKffr00Z49ewqdc/78eY0aNUrVq1dXxYoV1bdvXx09erTQOYcPH1ZSUpIiIiIUFRWlJ554QhcuXCjPt4L/b/r06YqPj7ffUDExMVHLly+3P894+odXXnlFJpNJjz76qP0YY+t7Jk2aJJPJVOirSZMm9ucZU9905MgR3XPPPapevbrCw8PVokUL/fjjj/bnffnnJYKThyxYsEDJycmaOHGi0tLS1LJlS3Xv3l3Hjh3zdNdwGTk5OWrZsqXeeeedYp9/7bXXNG3aNM2YMUMbNmxQhQoV1L17d50/f95+zuDBg7Vjxw6lpqZq6dKlWrt2rUaMGFFebwF/smbNGo0aNUrff/+9UlNTlZ+fr27duiknJ8d+zmOPPabPP/9cCxcu1Jo1a5SRkaE777zT/rzValVSUpLy8vL03Xffafbs2frwww/13HPPeeItBbyrrrpKr7zyijZt2qQff/xRN998s26//Xbt2LFDEuPpD3744Qe9++67io+PL3ScsfVNzZo1U2Zmpv1r3bp19ucYU9/z+++/q2PHjjKbzVq+fLl27typv//976patar9HJ/+ecmAR7Rv394YNWqU/bHVajVq1aplTJ482YO9QmlJMj755BP7Y5vNZsTExBhTpkyxHzt16pRhsViMefPmGYZhGDt37jQkGT/88IP9nOXLlxsmk8k4cuRIufUdl3fs2DFDkrFmzRrDMC6OodlsNhYuXGg/Z9euXYYkY/369YZhGEZKSooRFBRkZGVl2c+ZPn26ERkZaeTm5pbvG0CxqlatavzrX/9iPP3AmTNnjEaNGhmpqanGjTfeaIwdO9YwDD6rvmrixIlGy5Yti32OMfVNTz31lNGpU6fLPu/rPy8x4+QBeXl52rRpk7p06WI/FhQUpC5dumj9+vUe7BmcdfDgQWVlZRUa08qVKyshIcE+puvXr1eVKlXUrl07+zldunRRUFCQNmzYUO59RlGnT5+WJFWrVk2StGnTJuXn5xca1yZNmujqq68uNK4tWrRQdHS0/Zzu3bsrOzvbPssBz7BarZo/f75ycnKUmJjIePqBUaNGKSkpqdAYSnxWfdnevXtVq1Yt1a9fX4MHD9bhw4clMaa+6rPPPlO7du3Ur18/RUVFqXXr1po5c6b9eV//eYng5AEnTpyQ1Wot9EGXpOjoaGVlZXmoVyiLgnG70phmZWUpKiqq0PMhISGqVq0a4+4FbDabHn30UXXs2FHNmzeXdHHMQkNDVaVKlULn/nlcixv3gudQ/rZt26aKFSvKYrHooYce0ieffKKmTZsynj5u/vz5SktL0+TJk4s8x9j6poSEBH344YdasWKFpk+froMHD6pz5846c+YMY+qjDhw4oOnTp6tRo0b64osvNHLkSI0ZM0azZ8+W5Ps/L4V49NUBwEuMGjVK27dvL7S+Hr6pcePG2rJli06fPq1FixZp6NChWrNmjae7hTL45ZdfNHbsWKWmpiosLMzT3YGL9OjRw/7n+Ph4JSQkqG7duvrvf/+r8PBwD/YMzrLZbGrXrp1efvllSVLr1q21fft2zZgxQ0OHDvVw78qOGScPqFGjhoKDg4tUhjl69KhiYmI81CuURcG4XWlMY2JiihT/uHDhgk6ePMm4e9jo0aO1dOlSff3117rqqqvsx2NiYpSXl6dTp04VOv/P41rcuBc8h/IXGhqqhg0bqm3btpo8ebJatmypf/zjH4ynD9u0aZOOHTumNm3aKCQkRCEhIVqzZo2mTZumkJAQRUdHM7Z+oEqVKrrmmmu0b98+Pq8+KjY2Vk2bNi107Nprr7UvwfT1n5cITh4QGhqqtm3bauXKlfZjNptNK1euVGJiogd7BmfVq1dPMTExhcY0OztbGzZssI9pYmKiTp06pU2bNtnPWbVqlWw2mxISEsq9z7hYEnX06NH65JNPtGrVKtWrV6/Q823btpXZbC40rnv27NHhw4cLjeu2bdsK/SOfmpqqyMjIIv95wDNsNptyc3MZTx92yy23aNu2bdqyZYv9q127dho8eLD9z4yt7/vjjz+0f/9+xcbG8nn1UR07dixyW4+ffvpJdevWleQHPy95tDRFAJs/f75hsViMDz/80Ni5c6cxYsQIo0qVKoUqw8C7nDlzxti8ebOxefNmQ5IxdepUY/PmzcbPP/9sGIZhvPLKK0aVKlWMTz/91EhPTzduv/12o169esa5c+fs17j11luN1q1bGxs2bDDWrVtnNGrUyBg4cKCn3lLAGzlypFG5cmVj9erVRmZmpv3r7Nmz9nMeeugh4+qrrzZWrVpl/Pjjj0ZiYqKRmJhof/7ChQtG8+bNjW7duhlbtmwxVqxYYdSsWdMYP368J95SwBs3bpyxZs0a4+DBg0Z6eroxbtw4w2QyGV9++aVhGIynP7m0qp5hMLa+6PHHHzdWr15tHDx40Pj222+NLl26GDVq1DCOHTtmGAZj6os2btxohISEGC+99JKxd+9eY+7cuUZERIQxZ84c+zm+/PMSwcmD3nrrLePqq682QkNDjfbt2xvff/+9p7uEK/j6668NSUW+hg4dahjGxRKbEyZMMKKjow2LxWLccsstxp49ewpd47fffjMGDhxoVKxY0YiMjDSGDRtmnDlzxgPvBoZhFDuekowPPvjAfs65c+eMhx9+2KhataoRERFh3HHHHUZmZmah6xw6dMjo0aOHER4ebtSoUcN4/PHHjfz8/HJ+NzAMw/jrX/9q1K1b1wgNDTVq1qxp3HLLLfbQZBiMpz/5c3BibH1P//79jdjYWCM0NNSoXbu20b9/f2Pfvn325xlT3/T5558bzZs3NywWi9GkSRPjvffeK/S8L/+8ZDIMw/DMXBcAAAAA+Ab2OAEAAABACQhOAAAAAFACghMAAAAAlIDgBAAAAAAlIDgBAAAAQAkITgAAAABQAoITAAAAAJSA4AQAAAAAJSA4AQDgAJPJpCVLlni6GwCAckZwAgD4jPvuu08mk6nI16233urprgEA/FyIpzsAAIAjbr31Vn3wwQeFjlksFg/1BgAQKJhxAgD4FIvFopiYmEJfVatWlXRxGd306dPVo0cPhYeHq379+lq0aFGh9tu2bdPNN9+s8PBwVa9eXSNGjNAff/xR6JxZs2apWbNmslgsio2N1ejRows9f+LECd1xxx2KiIhQo0aN9Nlnn7n3TQMAPI7gBADwKxMmTFDfvn21detWDR48WAMGDNCuXbskSTk5OerevbuqVq2qH374QQsXLtRXX31VKBhNnz5do0aN0ogRI7Rt2zZ99tlnatiwYaHXeP7553X33XcrPT1dPXv21ODBg3Xy5MlyfZ8AgPJlMgzD8HQnAAAojfvuu09z5sxRWFhYoeNPP/20nn76aZlMJj300EOaPn26/bkOHTqoTZs2+uc//6mZM2fqqaee0i+//KIKFSpIklJSUtS7d29lZGQoOjpatWvX1rBhw/R///d/xfbBZDLp2Wef1YsvvijpYhirWLGili9fzl4rAPBj7HECAPiUv/zlL4WCkSRVq1bN/ufExMRCzyUmJmrLli2SpF27dqlly5b20CRJHTt2lM1m0549e2QymZSRkaFbbrnlin2Ij4+3/7lChQqKjIzUsWPHnH1LAAAfQHACAPiUChUqFFk65yrh4eGlOs9sNhd6bDKZZLPZ3NElAICXYI8TAMCvfP/990UeX3vttZKka6+9Vlu3blVOTo79+W+//VZBQUFq3LixKlWqpLi4OK1cubJc+wwA8H7MOAEAfEpubq6ysrIKHQsJCVGNGjUkSQsXLlS7du3UqVMnzZ07Vxs3btT7778vSRo8eLAmTpyooUOHatKkSTp+/LgeeeQR3XvvvYqOjpYkTZo0SQ899JCioqLUo0cPnTlzRt9++60eeeSR8n2jAACvQnACAPiUFStWKDY2ttCxxo0ba/fu3ZIuVrybP3++Hn74YcXGxmrevHlq2rSpJCkiIkJffPGFxo4dq+uuu04RERHq27evpk6dar/W0KFDdf78eb3xxhv629/+pho1auiuu+4qvzcIAPBKVNUDAPgNk8mkTz75RH369PF0VwAAfoY9TgAAAABQAoITAAAAAJSAPU4AAL/B6nMAgLsw4wQAAAAAJSA4AQAAAEAJCE4AAAAAUAKCEwAAAACUgOAEAAAAACUgOAEAAABACQhOAAAAAFACghMAAAAAlOD/AXMFOk7mKQjfAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oblivious Decision Tree model\n",
        "class ObliviousDecisionTree(nn.Module):\n",
        "    def __init__(self, train_x, train_y, depth=6, lr=0.01, epochs=50, optimizer_type='adam', loss_fn='mse', lr_scheduler=None):\n",
        "        super(ObliviousDecisionTree, self).__init__()\n",
        "        self.train_y = torch.tensor(train_y.values.ravel(), dtype=torch.float32).unsqueeze(1).to(device)\n",
        "        self.train_x = torch.tensor(train_x.to_numpy(), dtype=torch.float32).to(device)\n",
        "        self.input_dim = self.train_x.shape[1]\n",
        "        self.depth = depth\n",
        "\n",
        "        # Initialize feature selectors and thresholds for each depth level\n",
        "        self.feature_selectors = nn.ParameterList(\n",
        "            [nn.Parameter(torch.randn(self.input_dim)) for _ in range(depth)]\n",
        "        )\n",
        "        self.thresholds = nn.ParameterList(\n",
        "            [nn.Parameter(torch.randn(1)) for _ in range(depth)]\n",
        "        )\n",
        "\n",
        "        # Initialize leaf values (2^depth leaves)\n",
        "        self.leaf_values = nn.Parameter(torch.randn(2 ** depth))\n",
        "\n",
        "        # Loss Function\n",
        "        if loss_fn == 'mse': self.criterion = nn.MSELoss()\n",
        "        elif loss_fn == 'bce': self.criterion = nn.BCELoss()\n",
        "        else: raise ValueError(\"Unsupported loss function. Use 'mse' or 'bce'.\")\n",
        "\n",
        "        # Optimizer\n",
        "        if optimizer_type == 'adam': self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        elif optimizer_type == 'sgd': self.optimizer = optim.SGD(self.parameters(), lr=lr, momentum=0.9)\n",
        "        else: raise ValueError(\"Unsupported optimizer type. Use 'adam' or 'sgd'.\")\n",
        "\n",
        "        # Learning Rate Scheduler (optional)\n",
        "        self.lr_scheduler = None\n",
        "        if lr_scheduler == 'step': self.lr_scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.1)\n",
        "        elif lr_scheduler == 'plateau': self.lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n",
        "\n",
        "        # Number of training epochs\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        node_indices = torch.zeros(batch_size, dtype=torch.long).to(x.device)\n",
        "\n",
        "        for d in range(self.depth):\n",
        "            feature_selector = self.feature_selectors[d]\n",
        "            threshold = self.thresholds[d]\n",
        "            feature_value = torch.matmul(x, feature_selector)\n",
        "            go_right = feature_value > threshold\n",
        "            node_indices = (node_indices << 1) | go_right.long()\n",
        "        return self.leaf_values[node_indices].unsqueeze(1)\n",
        "odt = ObliviousDecisionTree(train_x, train_y, depth=3, lr=0.01, epochs=500, optimizer_type='adam', loss_fn='mse', lr_scheduler='step')\n",
        "odt.to(device)\n",
        "train_model_pt(odt)\n",
        "pred_train = predict_model_pt(odt, train_x)\n",
        "accuracy_train = calculate_accuracy_pt(odt, train_x, train_y, pred_train)\n",
        "pred_valid = predict_model_pt(odt, valid_x)\n",
        "accuracy_valid = calculate_accuracy_pt(odt, valid_x, valid_y, pred_valid)\n",
        "pred_test = predict_model_pt(odt, test_x)\n",
        "accuracy_test = calculate_accuracy_pt(odt, test_x, test_y, pred_test)\n",
        "print('Train pred:', pred_train)\n",
        "print('Train acc:', accuracy_train)\n",
        "print('Valid pred:', pred_valid)\n",
        "print('Valid acc:', accuracy_valid)\n",
        "print('Test pred:', pred_test)\n",
        "print('Test acc:', accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-xTf6Xyr9kq",
        "outputId": "3de4b170-fab4-4053-d357-143420e7a66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.141756296157837\n",
            "Epoch 5, Loss: 1.0622385740280151\n",
            "Epoch 10, Loss: 0.9878339171409607\n",
            "Epoch 15, Loss: 0.9178289175033569\n",
            "Epoch 20, Loss: 0.8519766330718994\n",
            "Epoch 25, Loss: 0.790435254573822\n",
            "Epoch 30, Loss: 0.7329530119895935\n",
            "Epoch 35, Loss: 0.6791958212852478\n",
            "Epoch 40, Loss: 0.6289980411529541\n",
            "Epoch 45, Loss: 0.582176923751831\n",
            "Epoch 50, Loss: 0.5385658740997314\n",
            "Epoch 55, Loss: 0.49804726243019104\n",
            "Epoch 60, Loss: 0.4604746401309967\n",
            "Epoch 65, Loss: 0.42569631338119507\n",
            "Epoch 70, Loss: 0.39356255531311035\n",
            "Epoch 75, Loss: 0.3639194965362549\n",
            "Epoch 80, Loss: 0.33662155270576477\n",
            "Epoch 85, Loss: 0.31152424216270447\n",
            "Epoch 90, Loss: 0.2884862422943115\n",
            "Epoch 95, Loss: 0.2673698961734772\n",
            "Epoch 100, Loss: 0.24804306030273438\n",
            "Epoch 105, Loss: 0.23037898540496826\n",
            "Epoch 110, Loss: 0.21425725519657135\n",
            "Epoch 115, Loss: 0.1995640993118286\n",
            "Epoch 120, Loss: 0.18619200587272644\n",
            "Epoch 125, Loss: 0.1740388572216034\n",
            "Epoch 130, Loss: 0.16300968825817108\n",
            "Epoch 135, Loss: 0.15301498770713806\n",
            "Epoch 140, Loss: 0.14396972954273224\n",
            "Epoch 145, Loss: 0.135796457529068\n",
            "Epoch 150, Loss: 0.12842290103435516\n",
            "Epoch 155, Loss: 0.12178028374910355\n",
            "Epoch 160, Loss: 0.11580504477024078\n",
            "Epoch 165, Loss: 0.11043864488601685\n",
            "Epoch 170, Loss: 0.1056271344423294\n",
            "Epoch 175, Loss: 0.10131989419460297\n",
            "Epoch 180, Loss: 0.0974707305431366\n",
            "Epoch 185, Loss: 0.09403662383556366\n",
            "Epoch 190, Loss: 0.09097836166620255\n",
            "Epoch 195, Loss: 0.08825951814651489\n",
            "Epoch 200, Loss: 0.08584652841091156\n",
            "Epoch 205, Loss: 0.08370906859636307\n",
            "Epoch 210, Loss: 0.08181902021169662\n",
            "Epoch 215, Loss: 0.08015081286430359\n",
            "Epoch 220, Loss: 0.07868100702762604\n",
            "Epoch 225, Loss: 0.07738842815160751\n",
            "Epoch 230, Loss: 0.07625390589237213\n",
            "Epoch 235, Loss: 0.07525987178087234\n",
            "Epoch 240, Loss: 0.07439044862985611\n",
            "Epoch 245, Loss: 0.07363138347864151\n",
            "Epoch 250, Loss: 0.0729699656367302\n",
            "Epoch 255, Loss: 0.07239465415477753\n",
            "Epoch 260, Loss: 0.07189511507749557\n",
            "Epoch 265, Loss: 0.07146214693784714\n",
            "Epoch 270, Loss: 0.0710875391960144\n",
            "Epoch 275, Loss: 0.07076402008533478\n",
            "Epoch 280, Loss: 0.07048508524894714\n",
            "Epoch 285, Loss: 0.07024502754211426\n",
            "Epoch 290, Loss: 0.07003875821828842\n",
            "Epoch 295, Loss: 0.06986184418201447\n",
            "Epoch 300, Loss: 0.06971035897731781\n",
            "Epoch 305, Loss: 0.06958087533712387\n",
            "Epoch 310, Loss: 0.0694703757762909\n",
            "Epoch 315, Loss: 0.06937626004219055\n",
            "Epoch 320, Loss: 0.0692962110042572\n",
            "Epoch 325, Loss: 0.06922823190689087\n",
            "Epoch 330, Loss: 0.06917061656713486\n",
            "Epoch 335, Loss: 0.06912185996770859\n",
            "Epoch 340, Loss: 0.0690806582570076\n",
            "Epoch 345, Loss: 0.06904590874910355\n",
            "Epoch 350, Loss: 0.06901663541793823\n",
            "Epoch 355, Loss: 0.068992018699646\n",
            "Epoch 360, Loss: 0.06897137314081192\n",
            "Epoch 365, Loss: 0.06895405799150467\n",
            "Epoch 370, Loss: 0.06893956661224365\n",
            "Epoch 375, Loss: 0.06892746686935425\n",
            "Epoch 380, Loss: 0.06891737133264542\n",
            "Epoch 385, Loss: 0.06890895962715149\n",
            "Epoch 390, Loss: 0.06890197098255157\n",
            "Epoch 395, Loss: 0.06889616698026657\n",
            "Epoch 400, Loss: 0.06889136880636215\n",
            "Epoch 405, Loss: 0.0688873901963234\n",
            "Epoch 410, Loss: 0.06888409703969955\n",
            "Epoch 415, Loss: 0.06888138502836227\n",
            "Epoch 420, Loss: 0.0688791424036026\n",
            "Epoch 425, Loss: 0.06887730211019516\n",
            "Epoch 430, Loss: 0.06887580454349518\n",
            "Epoch 435, Loss: 0.06887456029653549\n",
            "Epoch 440, Loss: 0.06887355446815491\n",
            "Epoch 445, Loss: 0.06887273490428925\n",
            "Epoch 450, Loss: 0.06887207180261612\n",
            "Epoch 455, Loss: 0.06887151300907135\n",
            "Epoch 460, Loss: 0.06887107342481613\n",
            "Epoch 465, Loss: 0.06887070834636688\n",
            "Epoch 470, Loss: 0.0688704177737236\n",
            "Epoch 475, Loss: 0.0688701793551445\n",
            "Epoch 480, Loss: 0.06886999309062958\n",
            "Epoch 485, Loss: 0.06886983662843704\n",
            "Epoch 490, Loss: 0.0688697099685669\n",
            "Epoch 495, Loss: 0.06886962056159973\n",
            "Train pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Train acc: 0.923898548034645\n",
            "Valid pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Valid acc: 0.9247222492288384\n",
            "Test pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Test acc: 0.9239634279188923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "class SVMClassifier():\n",
        "    def __init__(self, train_x, train_y, fraction=0.1, C=0.1, kernel='poly', degree=3, gamma='scale', n_estimators=6, max_samples=0.001, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the SVMClassifier with training data and optional parameters.\n",
        "\n",
        "        Parameters:\n",
        "        - train_x: Features for training.\n",
        "        - train_y: Labels for training.\n",
        "        - fraction: Fraction of data to sample (not used in this implementation).\n",
        "        - C: Penalty parameter C of the error term for SVM.\n",
        "        - kernel: Kernel type to be used in the SVM algorithm.\n",
        "        - degree: Degree of the polynomial kernel function (if kernel='poly').\n",
        "        - gamma: Kernel coefficient for 'rbf', 'poly', and 'sigmoid'.\n",
        "        - n_estimators: The number of base estimators in the Bagging ensemble.\n",
        "        - max_samples: The number of samples to draw from X to train each base estimator.\n",
        "        - random_state: Controls the randomness of the bootstrapping of the samples.\n",
        "        \"\"\"\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "        self.C = C\n",
        "        self.kernel = kernel\n",
        "        self.degree = degree\n",
        "        self.gamma = gamma\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_samples = max_samples\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.model = None\n",
        "        self.accuracies = []\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"Fits the SVM model using Bagging with the specified parameters.\"\"\"\n",
        "        self.model = BaggingClassifier(\n",
        "            estimator=SVC(C=self.C, kernel=self.kernel, degree=self.degree, gamma=self.gamma),\n",
        "            n_estimators=self.n_estimators,\n",
        "            max_samples=self.max_samples,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "        self.model.fit(self.train_x, self.train_y)\n",
        "        self._update_accuracy()\n",
        "\n",
        "    def _update_accuracy(self):\n",
        "        \"\"\"Internal method to update and store the model's accuracy on the training set.\"\"\"\n",
        "        predictions = self.model.predict(self.train_x)\n",
        "        accuracy = accuracy_score(self.train_y, predictions)\n",
        "        self.accuracies.append(accuracy)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predicts the labels for the given input data X.\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model has not been trained yet. Call `fit` before `predict`.\")\n",
        "        return self.model.predict(X).astype(float)\n",
        "\n",
        "    def calculate_accuracy(self, X, y, pred=None):\n",
        "        \"\"\"Calculates the accuracy of the model on the given data X and true labels y.\"\"\"\n",
        "        if pred is None: pred = self.predict(X)\n",
        "        return accuracy_score(y, pred)\n",
        "\n",
        "    def plot_training_curve(self):\n",
        "        \"\"\"Plots the training accuracy curve after fitting the model.\"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(range(1, len(self.accuracies) + 1), self.accuracies, marker='o', linestyle='-')\n",
        "        plt.title('SVM Training Accuracy Curve')\n",
        "        plt.xlabel('Iteration')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "svm = SVMClassifier(train_x, train_y)\n",
        "svm.fit()\n",
        "pred_train = svm.predict(train_x)\n",
        "accuracy_train = svm.calculate_accuracy(train_x, train_y, pred_train)\n",
        "pred_valid = svm.predict(valid_x)\n",
        "accuracy_valid = svm.calculate_accuracy(valid_x, valid_y, pred_valid)\n",
        "pred_test = svm.predict(test_x)\n",
        "accuracy_test = svm.calculate_accuracy(test_x, test_y, pred_test)\n",
        "print('Train pred:', pred_train)\n",
        "print('Train acc:', accuracy_train)\n",
        "print('Valid pred:', pred_valid)\n",
        "print('Valid acc:', accuracy_valid)\n",
        "print('Test pred:', pred_test)\n",
        "print('Test acc:', accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYEql8h9nL71",
        "outputId": "c88d5a5c-b46f-42ca-b2ca-966ee6a0651f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Train acc: 0.9288398158878607\n",
            "Valid pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Valid acc: 0.9298309189418513\n",
            "Test pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Test acc: 0.9290270233721742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NB\n",
        "class NaiveBayesClassifier():\n",
        "    def __init__(self, train_x, train_y):\n",
        "        \"\"\"\n",
        "        Initialize the NaiveBayesClassifier with training data and model parameters.\n",
        "\n",
        "        Parameters:\n",
        "        - train_x: Features for training.\n",
        "        - train_y: Labels for training.\n",
        "        - priors: Prior probabilities of the classes. If specified, the priors are not adjusted according to the data.\n",
        "        - var_smoothing: Portion of the largest variance of all features that is added to variances for stability.\n",
        "        \"\"\"\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "        self.accuracies = []\n",
        "\n",
        "        self.model = GaussianNB()\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"Fit the Naive Bayes model on the training data and track training accuracy.\"\"\"\n",
        "        self.model.fit(self.train_x, self.train_y)\n",
        "        accuracy = self._calculate_accuracy_internal(self.train_x, self.train_y)\n",
        "        self.accuracies.append(accuracy)\n",
        "\n",
        "    def _calculate_accuracy_internal(self, X, y):\n",
        "        \"\"\"Internal method to predict and calculate accuracy on the training data.\"\"\"\n",
        "        predictions = self.model.predict(X)\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict the labels for the input features X.\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model has not been trained yet. Call `fit` before `predict`.\")\n",
        "        return self.model.predict(X).astype(float)\n",
        "\n",
        "    def calculate_accuracy(self, X, y, pred=None):\n",
        "        \"\"\"\n",
        "        Calculate the accuracy of the model on the given data X and true labels y.\n",
        "\n",
        "        Parameters:\n",
        "        - X: Features for prediction.\n",
        "        - y: True labels.\n",
        "        - pred: Precomputed predictions (optional).\n",
        "\n",
        "        Returns:\n",
        "        - accuracy: Accuracy of the predictions.\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(X).astype(float) if pred is None else pred\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def plot_training_curve(self):\n",
        "        \"\"\"Plot the training accuracy curve after fitting the model.\"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(range(1, len(self.accuracies) + 1), self.accuracies, marker='o', linestyle='-')\n",
        "        plt.title('Naive Bayes Training Accuracy Curve')\n",
        "        plt.xlabel('Iteration')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "nb = NaiveBayesClassifier(train_x, train_y)\n",
        "nb.fit()\n",
        "pred_train = nb.predict(train_x)\n",
        "accuracy_train = nb.calculate_accuracy(train_x, train_y, pred_train)\n",
        "pred_valid = nb.predict(valid_x)\n",
        "accuracy_valid = nb.calculate_accuracy(valid_x, valid_y, pred_valid)\n",
        "pred_test = nb.predict(test_x)\n",
        "accuracy_test = nb.calculate_accuracy(test_x, test_y, pred_test)\n",
        "print('Train pred:', pred_train)\n",
        "print('Train acc:', accuracy_train)\n",
        "print('Valid pred:', pred_valid)\n",
        "print('Valid acc:', accuracy_valid)\n",
        "print('Test pred:', pred_test)\n",
        "print('Test acc:', accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSIRxIC7opts",
        "outputId": "a9c67546-ba5b-4259-c9d3-1e3486e1a134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train pred: [1. 0. 0. ... 0. 0. 0.]\n",
            "Train acc: 0.9322993272825678\n",
            "Valid pred: [1. 0. 0. ... 0. 0. 0.]\n",
            "Valid acc: 0.9330393049380861\n",
            "Test pred: [0. 0. 1. ... 0. 0. 0.]\n",
            "Test acc: 0.9322800453770275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RF\n",
        "class RandomForestModel():\n",
        "    def __init__(self, train_x, train_y, n_estimators=10, max_depth=None, random_state=42, max_samples=0.05, warm_start=True):\n",
        "        \"\"\"\n",
        "        Initialize the RandomForestModel with training data and hyperparameters.\n",
        "\n",
        "        Parameters:\n",
        "        - train_x: Features for training.\n",
        "        - train_y: Labels for training.\n",
        "        - n_estimators: The number of trees in the forest.\n",
        "        - max_depth: The maximum depth of the tree.\n",
        "        - random_state: Controls the randomness of the estimator.\n",
        "        - max_samples: The number of samples to draw from X to train each base estimator.\n",
        "        - warm_start: When set to True, reuse the solution of the previous call to fit.\n",
        "        \"\"\"\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "        self.accuracies = []\n",
        "\n",
        "        self.model = RandomForestClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            random_state=random_state,\n",
        "            max_samples=max_samples,\n",
        "            warm_start=warm_start\n",
        "        )\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"Fit the RandomForest model on the training data, tracking accuracy at each step.\"\"\"\n",
        "        for i in range(1, self.model.n_estimators + 1):\n",
        "            self.model.n_estimators = i\n",
        "            self.model.fit(self.train_x, self.train_y)\n",
        "            accuracy = self._calculate_accuracy_internal(self.train_x, self.train_y)\n",
        "            self.accuracies.append(accuracy)\n",
        "\n",
        "    def _calculate_accuracy_internal(self, X, y):\n",
        "        \"\"\"Internal method to predict and calculate accuracy on the training data.\"\"\"\n",
        "        predictions = self.model.predict(X)\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict the labels for the input features X.\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model has not been trained yet. Call `fit` before `predict`.\")\n",
        "        return self.model.predict(X).astype(float)\n",
        "\n",
        "    def calculate_accuracy(self, X, y, pred=None):\n",
        "        \"\"\"\n",
        "        Calculate the accuracy of the model on the given data X and true labels y.\n",
        "\n",
        "        Parameters:\n",
        "        - X: Features for prediction.\n",
        "        - y: True labels.\n",
        "        - pred: Precomputed predictions (optional).\n",
        "\n",
        "        Returns:\n",
        "        - accuracy: Accuracy of the predictions.\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(X).astype(float) if pred is None else pred\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def plot_training_curve(self):\n",
        "        \"\"\"Plot the training accuracy curve based on the number of trees in the forest.\"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(range(1, len(self.accuracies) + 1), self.accuracies, marker='o', linestyle='-')\n",
        "        plt.title('Random Forest Training Accuracy Curve')\n",
        "        plt.xlabel('Number of Trees')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "rf = RandomForestModel(train_x, train_y)\n",
        "rf.fit()\n",
        "pred_train = rf.predict(train_x)\n",
        "accuracy_train = rf.calculate_accuracy(train_x, train_y, pred_train)\n",
        "pred_valid = rf.predict(valid_x)\n",
        "accuracy_valid = rf.calculate_accuracy(valid_x, valid_y, pred_valid)\n",
        "pred_test = rf.predict(test_x)\n",
        "accuracy_test = rf.calculate_accuracy(test_x, test_y, pred_test)\n",
        "print('Train pred:', pred_train)\n",
        "print('Train acc:', accuracy_train)\n",
        "print('Valid pred:', pred_valid)\n",
        "print('Valid acc:', accuracy_valid)\n",
        "print('Test pred:', pred_test)\n",
        "print('Test acc:', accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gClO2PkCo077",
        "outputId": "56f4d4fd-ce87-43bc-db7a-1ad252b2a132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train pred: [1. 0. 0. ... 0. 0. 0.]\n",
            "Train acc: 0.9580304181204777\n",
            "Valid pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Valid acc: 0.9578137014875244\n",
            "Test pred: [0. 0. 1. ... 0. 0. 0.]\n",
            "Test acc: 0.9568242090949387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XBG\n",
        "class XGBoostClassifier():\n",
        "    def __init__(self, train_x, train_y, n_estimators=100, learning_rate=0.1, max_depth=6,\n",
        "                 subsample=0.8, colsample_bytree=0.8, gamma=0, reg_alpha=0, reg_lambda=1, eval_metric='error'):\n",
        "        \"\"\"\n",
        "        Initialize the XGBoostClassifier with training data and hyperparameters.\n",
        "\n",
        "        Parameters:\n",
        "        - train_x: Features for training.\n",
        "        - train_y: Labels for training.\n",
        "        - n_estimators: Number of trees in the ensemble.\n",
        "        - learning_rate: Step size shrinkage used to prevent ovexgbitting.\n",
        "        - max_depth: Maximum depth of a tree.\n",
        "        - subsample: Subsample ratio of the training instances.\n",
        "        - colsample_bytree: Subsample ratio of columns when constructing each tree.\n",
        "        - gamma: Minimum loss reduction required to make a further partition.\n",
        "        - reg_alpha: L1 regularization term on weights.\n",
        "        - reg_lambda: L2 regularization term on weights.\n",
        "        - eval_metric: Evaluation metric for cross-validation (default is 'error').\n",
        "        \"\"\"\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "\n",
        "        self.model = XGBClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            learning_rate=learning_rate,\n",
        "            max_depth=max_depth,\n",
        "            subsample=subsample,\n",
        "            colsample_bytree=colsample_bytree,\n",
        "            gamma=gamma,\n",
        "            reg_alpha=reg_alpha,\n",
        "            reg_lambda=reg_lambda,\n",
        "            eval_metric=eval_metric\n",
        "        )\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"Fit the XGBoost model on the training data.\"\"\"\n",
        "        self.model.fit(\n",
        "            self.train_x, self.train_y,\n",
        "            eval_set=[(self.train_x, self.train_y)],\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict the labels for the input features X.\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model has not been trained yet. Call `fit` before `predict`.\")\n",
        "        return self.model.predict(X).astype(float)\n",
        "\n",
        "    def calculate_accuracy(self, X, y, pred=None):\n",
        "        \"\"\"\n",
        "        Calculate the accuracy of the model on the given data X and true labels y.\n",
        "\n",
        "        Parameters:\n",
        "        - X: Features for prediction.\n",
        "        - y: True labels.\n",
        "        - pred: Precomputed predictions (optional).\n",
        "\n",
        "        Returns:\n",
        "        - accuracy: Accuracy of the predictions.\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(X).astype(float) if pred is None else pred\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def plot_training_curve(self):\n",
        "        \"\"\"Plot the training accuracy curve based on the model's evaluation results.\"\"\"\n",
        "        evals_result = self.model.evals_result()\n",
        "        error_values = evals_result['validation_0']['error']\n",
        "        accuracy_values = [1 - e for e in error_values]  # Convert error to accuracy\n",
        "        epochs = len(accuracy_values)\n",
        "        x_axis = range(epochs)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(x_axis, accuracy_values, marker='o', linestyle='-')\n",
        "        plt.title('XGBoost Training Accuracy Curve')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "xgb = XGBoostClassifier(train_x, train_y)\n",
        "xgb.fit()\n",
        "pred_train = xgb.predict(train_x)\n",
        "accuracy_train = xgb.calculate_accuracy(train_x, train_y, pred_train)\n",
        "pred_valid = xgb.predict(valid_x)\n",
        "accuracy_valid = xgb.calculate_accuracy(valid_x, valid_y, pred_valid)\n",
        "pred_test = xgb.predict(test_x)\n",
        "accuracy_test = xgb.calculate_accuracy(test_x, test_y, pred_test)\n",
        "print('Train pred:', pred_train)\n",
        "print('Train acc:', accuracy_train)\n",
        "print('Valid pred:', pred_valid)\n",
        "print('Valid acc:', accuracy_valid)\n",
        "print('Test pred:', pred_test)\n",
        "print('Test acc:', accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nt_B7kNo-td",
        "outputId": "e04a4ca7-41ed-422e-c071-49a2ffd0132d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train pred: [1. 0. 0. ... 0. 0. 0.]\n",
            "Train acc: 0.960472976661556\n",
            "Valid pred: [0. 0. 0. ... 0. 0. 0.]\n",
            "Valid acc: 0.9611193113018269\n",
            "Test pred: [0. 0. 1. ... 0. 0. 0.]\n",
            "Test acc: 0.9603627157099176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqCIknAetfip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cda8634b-5d1c-4288-c137-41c4cd414adc",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training estimator 1/5...\n",
            "We have to download the TabPFN, as there is no checkpoint at  /usr/local/lib/python3.10/dist-packages/tabpfn/models_diff/prior_diff_real_checkpoint_n_0_epoch_100.cpkt\n",
            "It has about 100MB, so this might take a moment.\n",
            "Training estimator 2/5...\n",
            "Training estimator 3/5...\n",
            "Training estimator 4/5...\n",
            "Training estimator 5/5...\n",
            "Bagging model training complete.\n",
            "Predicting with model 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting with model 2/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py:530: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=fp16_inference):\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-85a7c50113b8>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mtabpfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabPFNBagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mtabpfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mpred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabpfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0maccuracy_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabpfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mpred_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabpfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-85a7c50113b8>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, batch_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0my_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_winning_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, return_winning_probability, normalize_with_test)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_winning_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_with_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_with_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize_with_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, normalize_with_test, return_logits)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0meval_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         prediction = transformer_predict(self.model[2], X_full, y_full, eval_pos,\n\u001b[0m\u001b[1;32m    274\u001b[0m                                          \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                                          \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py\u001b[0m in \u001b[0;36mtransformer_predict\u001b[0;34m(model, eval_xs, eval_ys, eval_position, device, max_features, style, inference_mode, num_classes, extend_features, normalize_with_test, normalize_to_ranking, softmax_temperature, multiclass_decoder, preprocess_transform, categorical_feats, feature_shift_decoder, N_ensemble_configurations, batch_size_inference, differentiable_hps_as_style, average_logits, fp16_inference, normalize_with_sqrt, seed, no_grad, return_logits, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16_inference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0moutput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax_temperature_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;31m#print('MODEL INFERENCE TIME ('+str(batch_input.device)+' vs '+device+', '+str(fp16_inference)+')', str(time.time()-start))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;34m\"use_reentrant=False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             )\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         gen = _checkpoint_without_reentrant_generator(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tabpfn/scripts/transformer_prediction_interface.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(eval_xs, eval_ys, used_style, softmax_temperature, return_logits)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0minference_mode_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             output = model(\n\u001b[0m\u001b[1;32m    361\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mused_style\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_xs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mused_style\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_ys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                     single_eval_pos=eval_position)[:, :, 0:num_classes]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tabpfn/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, single_eval_pos)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msingle_eval_pos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_src\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_att_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_att_embeddings\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tabpfn/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tabpfn/layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0msingle_eval_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0msrc_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msingle_eval_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msingle_eval_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msingle_eval_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0msrc_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msingle_eval_position\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msingle_eval_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msingle_eval_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0msrc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_right\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1273\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1276\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5523\u001b[0m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaddbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5524\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5525\u001b[0;31m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5526\u001b[0m         \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title Testing\n",
        "# class TabPFNBagging():\n",
        "#     def __init__(self, train_x, train_y, n_estimators=10, sample_size=1000, device=device, N_ensemble_configurations=1):\n",
        "#         self.train_x = train_x\n",
        "#         self.train_y = train_y\n",
        "#         self.n_estimators = n_estimators\n",
        "#         self.sample_size = sample_size\n",
        "#         self.device = device\n",
        "#         self.N_ensemble_configurations = N_ensemble_configurations\n",
        "#         self.models = []\n",
        "#         self.X_sample, self.y_sample = None, None\n",
        "\n",
        "#     def fit(self):\n",
        "#         for i in range(self.n_estimators):\n",
        "#             print(f\"Training estimator {i + 1}/{self.n_estimators}...\")\n",
        "#             self.X_sample, self.y_sample = resample(self.train_x, self.train_y, n_samples=self.sample_size)\n",
        "#             model = TabPFNClassifier(device=self.device, N_ensemble_configurations=self.N_ensemble_configurations)\n",
        "#             model.fit(self.X_sample, self.y_sample, overwrite_warning=True)\n",
        "#             self.models.append(model)\n",
        "#         print(\"Bagging model training complete.\")\n",
        "\n",
        "#     def predict(self, X, batch_size=9000):\n",
        "#         n_samples = X.shape[0]\n",
        "#         n_batches = int(np.ceil(n_samples / batch_size))\n",
        "\n",
        "#         # Initialize predictions array\n",
        "#         predictions = np.zeros((n_samples, len(self.models)))\n",
        "\n",
        "#         for i, model in enumerate(self.models):\n",
        "#             print(f\"Predicting with model {i+1}/{self.n_estimators}...\")\n",
        "#             for batch_idx in range(n_batches):\n",
        "#                 start_idx = batch_idx * batch_size\n",
        "#                 end_idx = min(start_idx + batch_size, n_samples)\n",
        "#                 X_batch = X[start_idx:end_idx]\n",
        "\n",
        "#                 y_eval, prob = model.predict(X_batch, return_winning_probability=True)\n",
        "#                 predictions[start_idx:end_idx, i] = y_eval\n",
        "\n",
        "#         # Majority voting\n",
        "#         y_final = np.round(np.mean(predictions, axis=1)).astype(int)\n",
        "#         return y_final\n",
        "\n",
        "#     def calculate_accuracy(self, X, y, pred=None):\n",
        "#         y_pred = self.predict(X) if pred is None else pred\n",
        "#         accuracy = accuracy_score(y, y_pred)\n",
        "#         print(f\"Bagging model accuracy: {accuracy:.4f}\")\n",
        "#         return accuracy\n",
        "\n",
        "# tabpfn = TabPFNBagging(train_x, train_y)\n",
        "# tabpfn.fit()\n",
        "# pred_train = tabpfn.predict(train_x)\n",
        "# accuracy_train = tabpfn.calculate_accuracy(train_x, train_y, pred_train)\n",
        "# pred_valid = tabpfn.predict(valid_x)\n",
        "# accuracy_valid = tabpfn.calculate_accuracy(valid_x, valid_y, pred_valid)\n",
        "# pred_test = tabpfn.predict(test_x)\n",
        "# accuracy_test = tabpfn.calculate_accuracy(test_x, test_y, pred_test)\n",
        "# print('Train pred:', pred_train)\n",
        "# print('Train acc:', accuracy_train)\n",
        "# print('Valid pred:', pred_valid)\n",
        "# print('Valid acc:', accuracy_valid)\n",
        "# print('Test pred:', pred_test)\n",
        "# print('Test acc:', accuracy_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fkw5jbXSIpfK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Testing 2\n",
        "class Adaboost():\n",
        "    def __init__(self, classes_dict, train_x, train_y):\n",
        "        self.classes_dict = classes_dict\n",
        "        self.model_order = list(classes_dict.keys())\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "        self.trained_model = {}\n",
        "        self.training_data_history = {'base': {'X': self.train_x, 'y': self.train_y}}\n",
        "        self.current_weight = None\n",
        "        self.weight_history = {}\n",
        "        self.restart = False\n",
        "\n",
        "    def weight_init(self): self.current_weight = pd.Series(np.ones(len(self.train_y)) / len(self.train_y))\n",
        "\n",
        "    def weight_calculate(self, predictions, labels):\n",
        "        incorrect = predictions != labels.to_numpy()\n",
        "        error_rate = self.current_weight[incorrect].sum()\n",
        "\n",
        "        print('Error rate is:', error_rate)\n",
        "\n",
        "        if error_rate > 0.5:\n",
        "            self.weight_init()\n",
        "            self.restart = True\n",
        "            return\n",
        "\n",
        "        alpha = 0.5 * np.log((1 - error_rate) / error_rate)\n",
        "\n",
        "        # Update weights\n",
        "        self.current_weight[incorrect] *= np.exp(alpha)\n",
        "        self.current_weight[~incorrect] *= np.exp(-alpha)\n",
        "\n",
        "        # Normalize weights\n",
        "        self.current_weight /= self.current_weight.sum()\n",
        "\n",
        "    def training(self):\n",
        "        self.weight_init()\n",
        "        for model in self.model_order:\n",
        "            while True:\n",
        "                self.restart = False\n",
        "                self.train_x['weight'] = self.current_weight\n",
        "                self.train_y = self.train_y.to_frame()\n",
        "                self.train_y['weight'] = self.current_weight\n",
        "                sampled_train_x = self.train_x.sample(n=len(self.train_x), replace=True, weights='weight', random_state=42)\n",
        "                del self.train_x['weight']\n",
        "                del sampled_train_x['weight']\n",
        "                sampled_train_x.sort_index(inplace=True)\n",
        "                sampled_train_x.reset_index(drop=True, inplace=True)\n",
        "                sampled_train_y = self.train_y.sample(n=len(self.train_y), replace=True, weights='weight', random_state=42)\n",
        "                del self.train_y['weight']\n",
        "                self.train_y = self.train_y.iloc[:, 0]\n",
        "                del sampled_train_y['weight']\n",
        "                sampled_train_y.sort_index(inplace=True)\n",
        "                sampled_train_y.reset_index(drop=True, inplace=True)\n",
        "                sampled_train_y = sampled_train_y.iloc[:, 0]\n",
        "\n",
        "                print(\"*\" * 37)\n",
        "                print(f'Training --------------------- {model}')\n",
        "                current_model = self.classes_dict[model](sampled_train_x, sampled_train_y)\n",
        "                methods = inspect.getmembers(current_model, predicate=inspect.ismethod)\n",
        "\n",
        "                if 'fit' in [z for z, _ in methods]:\n",
        "                    current_model.fit()\n",
        "                    print('Finish training.\\nStart predicting.')\n",
        "                    current_prediction = current_model.predict(current_model.train_x)\n",
        "                    train_accuracy = current_model.calculate_accuracy(current_model.train_x , current_model.train_y, current_prediction)\n",
        "                else:\n",
        "                    current_model.to(device)\n",
        "                    train_model_pt(current_model)\n",
        "                    print('Finish training.\\nStart predicting.')\n",
        "                    current_prediction = predict_model_pt(current_model, current_model.train_x)\n",
        "                    train_accuracy = calculate_accuracy_pt(current_model, current_model.train_x, current_model.train_y, current_prediction)\n",
        "\n",
        "                print(f'{model} training accuracy:', train_accuracy)\n",
        "                self.weight_calculate(current_prediction, sampled_train_y)\n",
        "\n",
        "                if not self.restart:\n",
        "                    self.train_x, self.train_y = sampled_train_x, sampled_train_y\n",
        "                    self.training_data_history[model] = {'X': sampled_train_x, 'y': sampled_train_y}\n",
        "                    self.trained_model[model] = current_model\n",
        "                    break\n",
        "    def reorder(self, order_list): self.model_order = order_list\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Ensure X is a pandas DataFrame\n",
        "        assert isinstance(X, pd.DataFrame), \"Input X should be a pandas DataFrame\"\n",
        "        # Collect predictions from each trained model\n",
        "        model_predictions = {}\n",
        "        for model_name, model in self.trained_model.items():\n",
        "            methods = inspect.getmembers(model, predicate=inspect.ismethod)\n",
        "            if 'predict' in [z for z, _ in methods]: preds = model.predict(X)\n",
        "            else: preds = predict_model_pt(model, torch.tensor(X.to_numpy(), dtype=torch.float32).to(device))\n",
        "            assert isinstance(preds, np.ndarray), f\"Predictions from {model_name} should be a numpy array\"\n",
        "            if not np.array_equal(np.unique(preds), [0, 1]):\n",
        "                print('Alert --- ', np.unique(preds))\n",
        "                preds = np.where(preds > 0.5, 1, 0)\n",
        "            model_predictions[model_name] = preds\n",
        "        # Voting mechanism\n",
        "        predictions = np.zeros(len(X))\n",
        "        for i in range(len(X)):\n",
        "            votes = {}\n",
        "            for model_name, preds in model_predictions.items():\n",
        "                pred = preds[i]\n",
        "                if pred in votes: votes[pred] += 1\n",
        "                else: votes[pred] = 1\n",
        "            predictions[i] = max(votes, key=votes.get)\n",
        "        assert isinstance(predictions, np.ndarray), \"Final predictions should be a numpy array\"\n",
        "        return predictions\n",
        "\n",
        "    def calculate_accuracy(self, X, y, pred=None):\n",
        "        preds = pred if pred is not None else self.predict(X)\n",
        "        assert isinstance(preds, np.ndarray), \"Predictions should be a numpy array\"\n",
        "        assert isinstance(y, pd.Series), \"y should be a pandas Series\"\n",
        "        assert len(pred) == len(y), \"Predictions and y should have the same length\"\n",
        "        accuracy = np.mean(preds == y.to_numpy())\n",
        "        return accuracy\n",
        "adModel = Adaboost(classes_dict={\"tabpfn\":TabPFNBagging , \"lr\": LogisticRegressionModel, \"svm\": SVMClassifier, \"ann\": ANN, \"nb\": NaiveBayesClassifier, \"rf\": RandomForestModel, \"xgb\": XGBoostClassifier}, train_x=train_x, train_y=train_y)\n",
        "adModel.reorder(['svm', 'xgb', 'ann', 'rf', 'tabpfn'])\n",
        "adModel.training()\n",
        "print(\"*\" * 37)\n",
        "train_predict = adModel.predict(train_x)\n",
        "train_acc = adModel.calculate_accuracy(train_x, train_y, train_predict)\n",
        "test_predict = adModel.predict(test_x)\n",
        "test_acc = adModel.calculate_accuracy(test_x, test_y, test_predict)\n",
        "print(\"Adaboost model prediction: \", train_predict)\n",
        "print(\"Adaboost model training accuracy: \", train_acc)\n",
        "print(\"Adaboost model prediction: \", test_predict)\n",
        "print(\"Adaboost model training accuracy: \", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ2vWXWUydAs",
        "collapsed": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9wYZWNvWvKig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jDj7M0P0A_HT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}